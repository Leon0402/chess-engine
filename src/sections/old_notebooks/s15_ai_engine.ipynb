{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell",
     "no-python-export"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "with open('style.css') as file:\n",
    "    css = file.read()\n",
    "HTML(css)\n",
    "\n",
    "# Autload python modules by default\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Convert notebooks to python, so they can be loaded effiently\n",
    "from utils.jupyer_loader import JupyerLoader\n",
    "\n",
    "loader = JupyerLoader()\n",
    "loader.load(\"s04_engine_setup\")\n",
    "\n",
    "from converted_notebooks.s04_engine_setup import Engine, ScoredMove, RandomEngine, HumanEngine, playGame\n",
    "import chess\n",
    "import random\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "# AI Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "## Basic Evaluation Function\n",
    "\n",
    "The next engine is the first one\n",
    "to evaluate chess positions to find better moves. \n",
    "Instead of creating the `AbsoluteEvaluationEngine` as one block of code, method and attributes will be added dynamically one after another. This form of dynamic class modification is called monkey patching in the python community \n",
    "and is often used as a technique to patch third party code {cite}`plone:glossary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbsoluteEvaluationEngine(Engine):\n",
    "    \"\"\"Chess engine using the absolute value of the chessboard to evalute moves\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "\n",
    "A simple way of evaluating a move \n",
    "is based on absolute values for each piece.\n",
    "The dictionary `PIECE_VALUES` associates a chess piece type with a value as commonly defined in {cite}`Capablanca2006` and other books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIECE_VALUES = {\n",
    "    chess.PAWN: 1,\n",
    "    chess.KNIGHT: 3,\n",
    "    chess.BISHOP: 3,\n",
    "    chess.ROOK: 5,\n",
    "    chess.QUEEN: 9,\n",
    "    chess.KING: 0\n",
    "}\n",
    "\n",
    "AbsoluteEvaluationEngine.PIECE_VALUES = PIECE_VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "The evaluation of the game that is not finished is determined by summing up the piece values of the player to move\n",
    "and subtracting the piece values of the opponent.\n",
    "A positive score therefore is good for player to move whereas a negative score is good for the opponent. \n",
    "This is implemented in the method `_absolute_heuristic`,\n",
    "which takes a board as input and returns an integer representing this evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _absolute_heuristic(self, board: chess.Board) -> int:\n",
    "    \"\"\"Calculate the value of all pieces on the board\"\"\"\n",
    "\n",
    "    playerScore = sum(\n",
    "        self.PIECE_VALUES[board.piece_type_at(square)]\n",
    "        for square in chess.scan_reversed(board.occupied_co[board.turn])\n",
    "    )\n",
    "\n",
    "    opponentScore = sum(\n",
    "        self.PIECE_VALUES[board.piece_type_at(square)]\n",
    "        for square in chess.scan_reversed(board.occupied_co[not board.turn])\n",
    "    )\n",
    "\n",
    "    return playerScore - opponentScore\n",
    "\n",
    "\n",
    "AbsoluteEvaluationEngine._absolute_heuristic = _absolute_heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "For finished games a method `_evaluate` is definied.\n",
    "The `chess.Board` function `is_checkmate` can be used to determine if there is a winner. \n",
    "For a draw there are multiple functions vor various condiditions like `is_stalemate` or `is_insufficient_material`. \n",
    "To make the code more expressive a new function `is_draw` is added to the `chess.Board` class that checks for any of these conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_draw(self) -> bool:\n",
    "    \"\"\"Function to check for all any draw condition\"\"\"\n",
    "    return self.is_stalemate() or self.is_insufficient_material(\n",
    "    ) or self.is_fivefold_repetition() or self.is_seventyfive_moves()\n",
    "\n",
    "\n",
    "chess.Board.is_draw = is_draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "If the player to move was checkmated, the board is valued as `-100`, which is the lowest possible score. \n",
    "In case of a draw the board is valued as `0`. \n",
    "If the game is not finished `None` is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsoluteEvaluationEngine.VALUE_CHECKMATE = 100\n",
    "AbsoluteEvaluationEngine.VALUE_DRAW = 0\n",
    "\n",
    "\n",
    "def _evaluate(self, board: chess.Board) -> int:\n",
    "    \"\"\"Evaluate the current board\"\"\"\n",
    "    if board.is_checkmate():\n",
    "        return -self.VALUE_CHECKMATE\n",
    "    if board.is_draw():\n",
    "        return self.VALUE_DRAW\n",
    "    return None\n",
    "\n",
    "\n",
    "AbsoluteEvaluationEngine._evaluate = _evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "Both functions `_absolute_heuristic` and `_evaluate` are combined into a single `_evaluate_move` function to score a move. \n",
    "It takes a board and a move as a parameter and returns a scored move from the perspective of the White player. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsoluteEvaluationEngine.PLAYER_MULTIPLIER = {\n",
    "    chess.WHITE: 1, chess.BLACK: -1\n",
    "}\n",
    "\n",
    "\n",
    "def _evaluate_move(self, board: chess.Board, move: chess.Move) -> ScoredMove:\n",
    "    \"\"\"Evaluate a single move from white perspective\"\"\"\n",
    "\n",
    "    board.push(move)\n",
    "    score = self._evaluate(board)\n",
    "    if score is None:\n",
    "        score = self._absolute_heuristic(board)\n",
    "    score *= self.PLAYER_MULTIPLIER[board.turn]\n",
    "    board.pop()\n",
    "\n",
    "    return ScoredMove(score, move)\n",
    "\n",
    "\n",
    "AbsoluteEvaluationEngine._evaluate_move = _evaluate_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "Next, the `analyse` method can be defined to score all legal moves using the `_evaluate_move` method.\n",
    "\n",
    "The scored moves are then shuffled and, afterwards, sorted by their score, \n",
    "creating a different order of moves having the same score, \n",
    "depending on the state of the RNG.\n",
    "\n",
    "By default, the python `sort` method sorts from lowest to highest. \n",
    "Therefore, the first move is the best for Black, unless the sorting order is reversed.\n",
    "\n",
    "TODO: Explain _evaluate_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_moves(self, board: chess.Board):\n",
    "    return [self._evaluate_move(board, move) for move in board.legal_moves]\n",
    "\n",
    "\n",
    "AbsoluteEvaluationEngine._evaluate_moves = _evaluate_moves\n",
    "\n",
    "\n",
    "def analyse(self, board: chess.Board) -> list[ScoredMove]:\n",
    "    \"\"\"Analyse method using _absolute_heuristic\"\"\"\n",
    "    # TODO: Explain use of copy here\n",
    "    nextMoves = self._evaluate_moves(board.copy(stack=False))\n",
    "    random.shuffle(nextMoves)\n",
    "\n",
    "    whitesTurn = board.turn is chess.WHITE\n",
    "    nextMoves.sort(reverse=whitesTurn)\n",
    "\n",
    "    return nextMoves\n",
    "\n",
    "\n",
    "AbsoluteEvaluationEngine.analyse = analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "The `play` method will simply return the best move from `analyse` as an `chess.engine.PlayResult`. \n",
    "In case of having multiple best values, the taken move is random as the `analyse` shuffles the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(self, board: chess.Board) -> chess.engine.PlayResult:\n",
    "    bestScoredMove = self.analyse(board)[0]\n",
    "    return chess.engine.PlayResult(move=bestScoredMove.move, ponder=None)\n",
    "\n",
    "\n",
    "AbsoluteEvaluationEngine.play = play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "The `AbsoluteEnhancedRandomEngine` strategy is to capture everything the engine can. \n",
    "Additionally, it is also able to find mate in one. \n",
    "Therefore, it has very good chances to win against the `RandomEngine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "board = chess.Board()\n",
    "playGame(board, AbsoluteEvaluationEngine(), RandomEngine(), displayBoard=False)\n",
    "IPython.display.display(board)\n",
    "print(board.outcome())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "To verfify the correctness the `_absolute_heuristic` its output is checked against some famous chess games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "engine = AbsoluteEvaluationEngine()\n",
    "\n",
    "# TODO: Rewrite for _evaluate_move\n",
    "\n",
    "# Topalov, Veselin (2740) vs. Shirov, Alexei (2710)\n",
    "SHIROV_SACRIFICE = \"8/8/4kpp1/3p1b2/p6P/2B5/6P1/6K1 b - - 0 47\"\n",
    "board = chess.Board(SHIROV_SACRIFICE)\n",
    "#IPython.display.display(board)\n",
    "score = engine._evaluate(board)\n",
    "# Black has 2 points more and White moved last, so the score should be -2\n",
    "# assert score == -2, f\"{score} != -2\"\n",
    "\n",
    "# Evgeny Yuryevich Vladimirov vs. Vladimir Viktorovich Epishin\n",
    "VLADIMIROV_THUNDERBOLT = \"r4k1r/1b2bPR1/p4n2/3p4/4P2P/1q2B2B/PpP5/1K4R1 w - - 0 26\"\n",
    "board = chess.Board(VLADIMIROV_THUNDERBOLT)\n",
    "# IPython.display.display(board)\n",
    "# Black has 10 points more and Black moved last, so the score should be 10\n",
    "score = engine._evaluate(board)\n",
    "# assert score == 10, f\"{score} != 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "Additionally, a special chess position was constructed to test the `analyse` method. In this position, different moves such as capturings and promotions are possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "PROMOTION_POSITION = \"Kn2rn1k/1p2P3/8/8/8/8/8/8 w - - 0 1\"\n",
    "board = chess.Board(PROMOTION_POSITION)\n",
    "IPython.display.display(board)\n",
    "# Black has 11 points more and Black moved last, so the score should be 11\n",
    "score = engine._evaluate(board)\n",
    "# assert score == 11, f\"{score} != 11\"\n",
    "# Analyse scores are from the persective of the White Player!\n",
    "result = engine.analyse(board)\n",
    "assert result == [ScoredMove(0, chess.Move.from_uci(\"e7f8q\")),\n",
    "                  ScoredMove(-4, chess.Move.from_uci(\"e7f8r\")),\n",
    "                  ScoredMove(-6, chess.Move.from_uci(\"e7f8b\")),\n",
    "                  ScoredMove(-6, chess.Move.from_uci(\"e7f8n\")),\n",
    "                  ScoredMove(-10, chess.Move.from_uci(\"a8b7\")),\n",
    "                  ScoredMove(-11, chess.Move.from_uci(\"a8b7\"))], f'{result} is not correct'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "## Minimax Algorithm\n",
    "\n",
    "Until now, a move was evaluated according to the value the heuristic gives to the resulting position. Thus the chess engine lacks the foresight to find tactical combinations or a mate in several moves.\n",
    "With the help of a search algorithm all future positions can be found, which are created after playing a certain number of moves. {numref}`game-tree-figure` shows how the resulting positions in the game `TicTacToe` can be represented as a search tree. The root node is the initial position, while the leaf nodes contain the final positions that will be evaluated. A special feature of TicTacToe is that the leaf nodes are terminal states. In chess, on the other hand, the search usually has to be stopped at a certain depth, because the number of states is simply too large even for modern computers. The leaf nodes are therefore not necessarily terminal states and are thus evaluated with the already known heuristics. \n",
    "\n",
    "```{figure} ./images/tictactoe-gametree.jpg\n",
    "---\n",
    "height: 150px\n",
    "name: game-tree-figure\n",
    "---\n",
    "Sample TicTacToe search tree\n",
    "```\n",
    "\n",
    "TODO: This cite belongs to the figure\n",
    "{cite}`TicTacToe_Search_Tree`\n",
    "\n",
    "By limiting the search depth, however, the original problem is only partially solved. As before, it can happen that the considered final position ends, for example, in the middle of a slugfest and is correspondingly wrongly estimated. It also often leads to the fact that the engine tries to delay a foreseeable problem by giving chess etc. until it is no longer visible due to the search depth. \n",
    "This is called the horizon effect, which can have a very strong impact on the engine's playing strength and is discussed accordingly in later chapters.\n",
    "{cite}`Horizon_Effect`\n",
    "\n",
    "First, however, some search algorithms are presented, starting with the `MiniMax algorithm`. For this purpose, first a class `MiniMaxEngine` is defined, which inherits from `AbsoluteEvaluationEngine`, since for example the heuristic is reused. The constructor of the class initializes the attribute `look_ahead_depth`, which specifies the depth of the search tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniMaxEngine(AbsoluteEvaluationEngine):\n",
    "    \"\"\"Chess engine looking a fixed number of moves ahead using the minimax algorithm\"\"\"\n",
    "\n",
    "    def __init__(self, look_ahead_depth):\n",
    "        self.look_ahead_depth = look_ahead_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "The actual `MiniMax algorithm` is realized recursively with the function `_value`. This function creates the search tree and takes the board and the remaining depth of the current node of the search tree as parameters. In each recursive pass, the method returns the value of the current node from the perspective of white. \n",
    "\n",
    "First, the method `_evaluate` checks whether the current position is a terminal state. If this is the case, the evaluation of this from the perspective of white is returned accordingly. \n",
    "Otherwise, it is checked whether the maximum search depth has been reached and it is therefore a leaf node. In this case the heuristic method `_absolute_heuristic` is used and the value from the perspective of white is returned.\n",
    "\n",
    "If neither of the termination conditions is true, the recursive part of the method is executed. For each possible move the new position is generated and recursively calculated with `_value`. In total, a list of values is generated for each child node in the search tree. \n",
    "\n",
    "Finally, the question remains how the node itself is evaluated based on the evaluations of the child nodes. The key idea of the `MiniMax algorithm` is that there is a minimizing and a maximizing player. When it is White's turn, he tries to maximize the valuation for his move. Accordingly, in this case the maximum value of the child nodes is returned. If, on the other hand, it is black's turn, he tries to minimize the valuation for his move. Therefore, the minimum value of the child nodes is returned. \n",
    "Overall, the algorithm assumes that both players want to win and play the best move for themselves. The respective position is thus evaluated as the future position that would be reached if both players played optimally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _value(self, board: chess.Board, depth: int) -> int:\n",
    "    if score := self._evaluate(board):\n",
    "        return self.PLAYER_MULTIPLIER[board.turn] * score\n",
    "    if depth == 0:\n",
    "        return self.PLAYER_MULTIPLIER[board.turn\n",
    "                                      ] * self._absolute_heuristic(board)\n",
    "\n",
    "    scores = []\n",
    "    for move in board.legal_moves:\n",
    "        board.push(move)\n",
    "        scores.append(self._value(board, depth - 1))\n",
    "        board.pop()\n",
    "\n",
    "    if board.turn is chess.WHITE:\n",
    "        return max(scores)\n",
    "    else:\n",
    "        return min(scores)\n",
    "\n",
    "\n",
    "MiniMaxEngine._value = _value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, only the `_evaluate_move` must be adjusted so that it calculates the value of the move using the `_value` function just defined. The function is initially called with the maximum search depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_move(self, board: chess.Board, move: chess.Move):\n",
    "    board.push(move)\n",
    "    score = self._value(board, self.look_ahead_depth)\n",
    "    board.pop()\n",
    "    return ScoredMove(score=score, move=move)\n",
    "\n",
    "\n",
    "MiniMaxEngine._evaluate_move = _evaluate_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate how the algorithm works, a special chess position is constructed in which only a limited number of moves are possible and the evaluation varies greatly depending on the move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_minimax_board = chess.Board(\"7k/7P/7P/8/8/p7/8/7K b - - 0 1\")\n",
    "IPython.display.display(sample_minimax_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An additional auxiliary class `MinMaxTree` was written, which however only serves to visualize the search tree and is therefore not explained in more detail. An instance of the class can be created with the method `add_tree_to_engine`. If then a position is analyzed with `analyze`, the tree can be drawn afterwards with `draw`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MinMaxTree\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "engine = MiniMaxEngine(look_ahead_depth=2)\n",
    "tree = MinMaxTree.add_tree_to_engine(engine)\n",
    "print(engine.analyse(sample_minimax_board))\n",
    "tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the constructed example, the search tree can still be well surveyed. This is due in particular to the low branching factor in the first two moves. On average, however, the branching factor is 35 - 38 {cite}`Branching_Factor`. As a consequence, the number of nodes with higher depth quickly exceeds the computational capacity of modern computers. \n",
    "\n",
    "The following position, which arises from the Exchange Variation of the Declined Queen's Gambit, will demonstrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middlegame_board = chess.Board(\n",
    "    \"r1bqrnk1/pp2bppp/2p2n2/3p2B1/3P4/2NBPN2/PPQ2PPP/R4RK1 w - - 7 11\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.display(middlegame_board)\n",
    "print(f\"Number of moves: {len(list(middlegame_board.legal_moves))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this position is evaluated with the `MiniMaxEngine` at depth two, it is immediately noticeable that the calculation is considerably slower. The evaluation of the tree also shows that it contains a total of over 70'000 nodes. At a depth of three, the number of nodes increases to 2'342'944. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "engine = MiniMaxEngine(look_ahead_depth=2)\n",
    "tree = MinMaxTree.add_tree_to_engine(engine)\n",
    "result_minimax = engine.analyse(middlegame_board)\n",
    "print(result_minimax)\n",
    "tree.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaBeta Pruning Algorithm\n",
    "\n",
    "The previous example makes clear that the primary goal to increase the search depth must be a reduction of the nodes. The `MiniMax algorithm` is a depth-first search where the paths have to be evaluated completely one after the other. If it is the maximizing player's turn, i.e. white, the first evaluation of the path gives the minimum value white can reach. Each further path must exceed this value so that it is ultimately played by white. Similarly, for black on the move, each further path must undercut the previous value for it to be played by black. \n",
    "\n",
    "The `AlphaBeta Pruning Algorithm` builds on this idea and introduces two additional parameters `alpha` and `beta` for the `_value` function. `alpha` is the value that the current position has at least and beta is the value that the position has at most. Therefore `alpha <= _value(board, depth, alpha, beta) <= beta` holds.\n",
    "\n",
    "First, a new class `AlphaBetaEngine` is defined again, which inherits from `MiniMaxEngine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaBetaEngine(MiniMaxEngine):\n",
    "    \"\"\"Chess engine looking a fixed number of moves ahead using the alpha beta pruning algorithm\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_value` function has the same interface as before except for the two new parameters `alpha` and `beta`. The termination conditions of the recursive function are also the same. \n",
    "\n",
    "For the maximizing player, hence the white player, `alpha` stores the current best score that can be achieved in that position. For each child node, alpha is therefore incremented with the statement `alpha = max(alpha, value)` if its value is higher. However, if `alpha` or the score of a child node is greater than `beta`, the search can be terminated prematurely. This is called a `beta cutoff`. The reason for this is that with `beta` Black could already achieve a better score for himself in another position and thus will not let White get into the current situation at all. Thus it is of no use to White to analyze the further moves. \n",
    "\n",
    "The same applies to the minimizing player. His currently best score is stored in `beta` and always lowered with the instruction `beta = min(beta, value)` if a child node has a low and therefore better value for black. If `beta` or the value of the child node is below `alpha`, the search can be aborted. This is called an `alpha cutoff`. Here, too, White had already found a better move for himself one level higher with `alpha` and will therefore not let Black get into this position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _value(self, board: chess.Board, depth: int, alpha: int, beta: int) -> int:\n",
    "    if score := self._evaluate(board):\n",
    "        return self.PLAYER_MULTIPLIER[board.turn] * score\n",
    "    if depth == 0:\n",
    "        return self.PLAYER_MULTIPLIER[board.turn\n",
    "                                      ] * self._absolute_heuristic(board)\n",
    "\n",
    "    if board.turn is chess.WHITE:\n",
    "        for move in board.legal_moves:\n",
    "            board.push(move)\n",
    "            value = self._value(board, depth - 1, alpha, beta)\n",
    "            board.pop()\n",
    "            if value >= beta:\n",
    "                return value\n",
    "            alpha = max(alpha, value)\n",
    "\n",
    "        return alpha\n",
    "    else:\n",
    "        for move in board.legal_moves:\n",
    "            board.push(move)\n",
    "            value = self._value(board, depth - 1, alpha, beta)\n",
    "            board.pop()\n",
    "            if alpha >= value:\n",
    "                return value\n",
    "            beta = min(beta, value)\n",
    "\n",
    "        return beta\n",
    "\n",
    "\n",
    "AlphaBetaEngine._value = _value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the `_evaluate_move` method must be adapted. This is identical to the implementation of the `MiniMaxEngine` with exception of the `_value` call. There you have to pass an initial value for `alpha` and `beta`. Since no move has been played yet, White can in any case achieve the worst possible result, he is set to mate. Accordingly `alpha` is initialized with `-self.VALUE_CHECKMATE`. The best possible result for white is to set mate himself, accordingly `beta` is initialized with `self.VALUE_CHECKMATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_move(self, board: chess.Board, move: chess.Move):\n",
    "    board.push(move)\n",
    "    score = self._value(\n",
    "        board,\n",
    "        self.look_ahead_depth,\n",
    "        -self.VALUE_CHECKMATE,\n",
    "        self.VALUE_CHECKMATE\n",
    "    )\n",
    "    board.pop()\n",
    "    return ScoredMove(score=score, move=move)\n",
    "\n",
    "\n",
    "AlphaBetaEngine._evaluate_move = _evaluate_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `AlphaBetaEngine` can evaluate the same constructed position `sample_minimax_board`. You can see in the graph that some nodes are marked with a question mark. These are the nodes that in this case did not have to be evaluated, because the result of the parent node was already defined before due to alpha and beta cutoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "engine = AlphaBetaEngine(look_ahead_depth=2)\n",
    "# engine = AlphaBetaEngine(look_ahead_depth=3)\n",
    "tree = MinMaxTree.add_tree_to_engine(engine)\n",
    "print(engine.analyse(sample_minimax_board))\n",
    "tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second position 'middlegame_board', the number of nodes can again be calculated for depths two and three. At a depth of two, with 7'459 only about 10% of the previous nodes have to be examined, 62'660 paths were pruned. At a depth of three, with 10,7628 nodes only about 5% of the previous nodes have to be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "engine = AlphaBetaEngine(look_ahead_depth=2)\n",
    "# engine = AlphaBetaEngine(look_ahead_depth=3)\n",
    "tree = MinMaxTree.add_tree_to_engine(engine)\n",
    "result_alphabeta = engine.analyse(middlegame_board)\n",
    "tree.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the operation of the algorithm, it is obvious that it is advantageous if the best path is evaluated first. In the best case, it is possible that the `x` nodes considered at `MiniMax` decrease to `sqrt(x)` when `Alpha Beta Pruning` is applied. If, on the other hand, the moves are sorted the other way around, so that the worst path is started with, no pruning is possible at all. {cite}`Alpha_Beta`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NegaMax Algorithmus \n",
    "\n",
    "The `NegaMax algorithm` does not lead to a direct improvement of the engine, but simplifies the code of the `MiniMax algorithm` and all algorithms based on it. The basic idea here is that the evaluation of each node is done from the perspective of the player on the move. Thus both players are maximizing and the previous case distinction is no longer necessary. \n",
    "\n",
    "For the previous implementation of `_value` for the `AlphaBeta Pruning Algorithm`, this first of all changes the return values of the termination conditions. Since the value is now from the perspective of the player on the move and the functions `_evaluate` and `_absolute_heuristic` also evaluate from the perspective of the player on the move, the value can be returned directly. \n",
    "Furthermore, the case distinction is completely omitted and only the code for the maximizing player is needed. There the recursive call of the `_value` function changes to `value = -1 * self._value(board, depth - 1, -beta, -alpha)`. The return value, as well as alpha and beta, are negated to be from the player's perspective on the move. Additionally, alpha and beta must be swapped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _value(self, board: chess.Board, depth: int, alpha: int, beta: int) -> int:\n",
    "    if score := self._evaluate(board):\n",
    "        return score\n",
    "    if depth == 0:\n",
    "        return self._absolute_heuristic(board)\n",
    "\n",
    "    for move in board.legal_moves:\n",
    "        board.push(move)\n",
    "        value = -1 * self._value(board, depth - 1, -beta, -alpha)\n",
    "        board.pop()\n",
    "        if value >= beta:\n",
    "            return value\n",
    "        alpha = max(alpha, value)\n",
    "\n",
    "    return alpha\n",
    "\n",
    "\n",
    "AlphaBetaEngine._value = _value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_evaluate_move` needs to be adjusted so that its returned result is again from the perspective of white as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_move(self, board: chess.Board, move: chess.Move):\n",
    "    board.push(move)\n",
    "    score = self._value(\n",
    "        board,\n",
    "        self.look_ahead_depth,\n",
    "        -self.VALUE_CHECKMATE,\n",
    "        self.VALUE_CHECKMATE\n",
    "    )\n",
    "    score *= self.PLAYER_MULTIPLIER[board.turn]\n",
    "    board.pop()\n",
    "    return ScoredMove(score=score, move=move)\n",
    "\n",
    "\n",
    "AlphaBetaEngine._evaluate_move = _evaluate_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `middlegame_board` position can also be analyzed by the `NegaMax` variant and afterwards it can be verified that all three implementations actually evaluate the position in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "engine = AlphaBetaEngine(look_ahead_depth=2)\n",
    "tree = MinMaxTree.add_tree_to_engine(engine, relative=True)\n",
    "result_negamax = engine.analyse(middlegame_board)\n",
    "tree.count()\n",
    "\n",
    "assert result_minimax == result_alphabeta == result_negamax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Deepening\n",
    "\n",
    "The algorithms shown so far have the advantage of a low memory consumption, as usual in a depth-first searches. Thus, at most the current path must always be kept in memory. A disadvantage is, however, that it is difficult to build in a time break. If the search is simply aborted after a certain time, some paths have been evaluated completely, while other paths have not been considered at all. Another problem currently with the `AlphaBeta Pruning Algorithm` is that in the optimal case, good moves should be considered first, in order to be able to prune as many paths as possible. So far, however, there is no heuristic to perform this sorting of the moves.\n",
    "\n",
    "The idea of iterative depth-first search provides a possible solution to both problems. In contrast to the normal depth-first search, the depth is iteratively increased until the maximum depth is reached. The obvious disadvantage of this is more overhead, since nodes that have already been analyzed are looked at again in the next iterative pass. However, as seen in previous examples, the number of new nodes increases so dramatically for each increase in search depth that re-analyzing previous nodes is negligible.\n",
    "\n",
    "The advantage of iterative depth-first search, however, is that the results obtained from previous runs with lower search depths can be used. On the one hand, these results can be returned if the time limit expires in the next run. On the other hand, based on the previous run, the sorting of moves for the next one can be done. \n",
    "\n",
    "At first only the iterative deepening algorithmn itself shall be implemented in a new class `IterativeAlphaBeta`, which inherits from `AlphaBetaEngine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeAlphaBeta(AlphaBetaEngine):\n",
    "    \"\"\"Chess engine looking a fixed number of moves ahead using the alpha beta pruning algorithm\"\"\"\n",
    "\n",
    "    def __init__(self, max_look_ahead_depth):\n",
    "        self.max_look_ahead_depth = max_look_ahead_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_evaluate_move` method must be adapted so that the depth is now a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_move(self, board: chess.Board, move: chess.Move, depth: int):\n",
    "    board.push(move)\n",
    "    score = self._value(\n",
    "        board, depth, -self.VALUE_CHECKMATE, self.VALUE_CHECKMATE\n",
    "    )\n",
    "    score *= self.PLAYER_MULTIPLIER[board.turn]\n",
    "    board.pop()\n",
    "    return ScoredMove(score=score, move=move)\n",
    "\n",
    "\n",
    "IterativeAlphaBeta._evaluate_move = _evaluate_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `_evaluate_moves` method, a simple loop can now be built in, which increases the depth step by step until the desired maximum depth is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_moves(self, board: chess.Board):\n",
    "    print(f\"Max depth: {self.max_look_ahead_depth}\")\n",
    "\n",
    "    for depth in range(self.max_look_ahead_depth + 1):\n",
    "        scoredMoves = [\n",
    "            self._evaluate_move(board, move, depth)\n",
    "            for move in board.legal_moves\n",
    "        ]\n",
    "\n",
    "        print(f\"Depth {depth}\")\n",
    "        # print(f\"result: {scoredMoves}\\n\")\n",
    "\n",
    "    return scoredMoves\n",
    "\n",
    "\n",
    "IterativeAlphaBeta._evaluate_moves = _evaluate_moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, it can be verified that the new implementation still evaluates the already known position in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "engine = IterativeAlphaBeta(max_look_ahead_depth=2)\n",
    "result_iterativeAlphaBeta = engine.analyse(middlegame_board)\n",
    "\n",
    "assert result_iterativeAlphaBeta == result_negamax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpositionstabellen\n",
    "\n",
    "In the last section of this chapter we will look at transposition tables. Essentially, they are a cache for the search tree that serves several purposes. The first use case and eponym are transpositions. In chess one speaks of a transposition, if the same position is obtained by different move sequences. In this case, with the help of a cache, the position has to be evaluated only once. In some algorithms, such as the 'MDTF algorithm', a node of the search tree is also evaluated several times in succession. In this case it is therefore possible to fall back on the already calculated results in the cache. Finally, it is also possible, e.g. in an iterative deepening framework, to perform move ordering after a search pass through the cache. A possible implementation of the `principal variation search`, for example, uses the cache to determine the principal variation of the previous search pass.\n",
    "\n",
    "First, we have to consider how an entry in the cache is structured. Besides the value of a node, the depth for which this value is valid is of course important. Furthermore, it could be seen with the `AlphaBeta algorithm` that it performs optimizations based on the `alpha` and `beta` value and thus on previously considered other paths in the tree. Thus, the value is not necessarily valid in a transposition that was reached by other means. One possibility would therefore be to store `alpha` and `beta` as well. \n",
    "\n",
    "A more meaningful way, however, is to classify the different nodes within a search tree:\n",
    "\n",
    "1. `alpha < score < beta`: All child nodes have been examined and the value is always exact, even for transpositions. This is often referred to as `PV-Node`.\n",
    "1. `alpha < beta <= score`: The search was aborted by a beta cut, therefore it is also called a `Cut-Node`. The score here is a lower limit, the actual value could be larger. \n",
    "1. `score <= alpha < beta`: Here all child nodes were examined too, however beta cutoffs occured. These nodes are also referred to as `All-Node`. Here the value acts as an upper bound, the actual value could be lower. \n",
    "\n",
    "In general it can be said that at least the root node and the leftmost node must be `PV-Nodes`, because `alpha` and `beta` cannot cause cuttofs there yet. The children of `PV-Nodes` can in turn also be `PV-Nodes` or `Cut-Nodes` if a beta cuttoff has occurred. After `Cut-Nodes` follow in each case alternating `All Nodes` and again `Cut-Nodes`. cite:[Node_Types].\n",
    "\n",
    "The node type is stored in an enum. As designation the effect of the value was chosen, therefore, whether this is exact, a lower limit or an upper limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class NodeType(Enum):\n",
    "    EXACT = 0  # PV Node\n",
    "    LOWER_BOUND = 1  # Cut Node\n",
    "    UPPER_BOUND = 2  # All Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this a dedicated data class is created\n",
    "to store the node type, value and depth of a position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CachedPositionEntry:\n",
    "    type: NodeType\n",
    "    value: int\n",
    "    depth: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dedicated class `AlphaBetaCache` is created\n",
    "to provide an abstraction for storing and loading entries.\n",
    "The entries are interally stored in a `dict` \n",
    "and wrapped methods are provided to reset the cache\n",
    "or get its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaBetaCache:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cache = dict()\n",
    "\n",
    "    def clear(self):\n",
    "        self.cache.clear()\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a cache entry their needs to be a key to identify the position.\n",
    "This key is calculated using the method `get_key`,\n",
    "which takes a board as input and returns a key representing the position in a unique way.\n",
    "As this function is called wether there is a matching cached entry or not\n",
    "it needs to be fast.\n",
    "A popular way of identifying positions in chess engines is the usage of Zobrist Hashes,\n",
    "as they can be determined incrementally cite:[Zobrist_Hashing].\n",
    "As the `python-chess` library already has an internal method `_transposition_key`\n",
    "this is used.\n",
    "It is rather quick\n",
    "as only internal representations of the position are used to calculate it\n",
    "and the calculation is already done on every `push` and `pop`.\n",
    "To use Zobrist Hashes in a useful way\n",
    "the `python-chess` library would need to be patched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(self, board: chess.Board):\n",
    "    return board._transposition_key()\n",
    "\n",
    "\n",
    "AlphaBetaCache.get_key = get_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save an entry to the cache its node type needs to be calculated.\n",
    "This is done by the auxilary function `_get_node_type`\n",
    "which takes a value, the depth, alpha and beta as parameters and returns the node type.\n",
    "It implements the typing as described above \n",
    "and additionally recognizes the leaf nodes as PV Nodes by their depth of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_node_type(self, value: int, depth: int, alpha: int, beta: int):\n",
    "    # TODO: Correct in some cases, but not all (for instance with quiescene search, which does cutoffs)\n",
    "    # if depth == 0:\n",
    "    #     return NodeType.EXACT\n",
    "    if value <= alpha:\n",
    "        return NodeType.UPPER_BOUND\n",
    "    if value >= beta:\n",
    "        return NodeType.LOWER_BOUND\n",
    "    return NodeType.EXACT\n",
    "\n",
    "\n",
    "AlphaBetaCache._get_node_type = _get_node_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `store_cache` method\n",
    "adds an entry \n",
    "defined by the key returned by the `get_key` method\n",
    "to the cache.\n",
    "The entry consists of the node type as returned by the `_get_node_type` method,\n",
    "the value and the current depth.\n",
    "The parameters are therefore the parameters of `_get_node_type` (value, alpha, beta) and the key.\n",
    "\n",
    "Initially the cache is checked for an already existing entry.\n",
    "If there is a matching entry and its depth is deeper than the current depth, \n",
    "the current value is not stored in the cache \n",
    "as the other value has been calculated using more ressources already.\n",
    "This is called depth first replacement\n",
    "and is a popular way to handle replacing cache values,\n",
    "but it is not the only way to do so. \n",
    "If there is no such entry,\n",
    "the node type is evaluated and the tuple as described above is added to the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_cache(self, key: int, value: int, depth: int, alpha: int, beta: int):\n",
    "    # depth first replacement\n",
    "    entry = self.cache.get(key)\n",
    "    if entry and entry.depth >= depth:\n",
    "        return\n",
    "\n",
    "    node_type = self._get_node_type(value, depth, alpha, beta)\n",
    "    self.cache[key] = CachedPositionEntry(node_type, value, depth)\n",
    "\n",
    "\n",
    "AlphaBetaCache.store_cache = store_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_cache` method returns an entry and it's type from the cache given a key.\n",
    "Additionaly the depth is supplied as a parameter\n",
    "as the cache entry is only relevant \n",
    "if it has the same or a greater depth.\n",
    "If there is no matching entry\n",
    "or the depth of the cached value is too shallow\n",
    "a `KeyError` exception is thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cache(self, key: int, depth: int):\n",
    "    entry = self.cache[key]\n",
    "    if entry.depth < depth:\n",
    "        raise KeyError\n",
    "\n",
    "    return (entry.type, entry.value)\n",
    "\n",
    "\n",
    "AlphaBetaCache.load_cache = load_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `AlphaBetaCache` is fully implemented,\n",
    "but to use it the `_value` needs to be aware of it.\n",
    "Therefore a decorator `cache_alpha_beta` is created\n",
    "to check the cache for a matching entry\n",
    "and to store the new result\n",
    "if there was no matching entry yet.\n",
    "\n",
    "The decorator calculates the key for the current position \n",
    "and tries to get a matching entry from the cache \n",
    "via `load_cache`.\n",
    "If there is such an entry a differentiation needs to be made;\n",
    "an exact value can be returned immediately\n",
    "while a lower bound may increase `alpha`\n",
    "and an upper bound may decrease `beta`.\n",
    "This might lead to a cutoff\n",
    "in case the new `alpha` is at least `beta`\n",
    "and the cached value being returned immediately.\n",
    "\n",
    "If the value is not returned immediately\n",
    "or there was no value in the cache at all\n",
    "the `value_function` is called\n",
    "and the returned value is stored in the cache via `store_cache`\n",
    "before returning the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "\n",
    "def cache_alpha_beta(value_function):\n",
    "\n",
    "    @wraps(value_function)\n",
    "    def cached_value(\n",
    "        self, board: chess.Board, depth: int, alpha: int, beta: int\n",
    "    ):\n",
    "        cacheKey = self.cache.get_key(board)\n",
    "        try:\n",
    "            type, value = self.cache.load_cache(cacheKey, depth)\n",
    "\n",
    "            if type == NodeType.EXACT:\n",
    "                return value\n",
    "            elif type == NodeType.LOWER_BOUND:\n",
    "                alpha = max(value, alpha)\n",
    "            else:  # type == NodeType.UPPER_BOUND\n",
    "                beta = min(value, beta)\n",
    "\n",
    "            if alpha >= beta:\n",
    "                return value\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        value = value_function(self, board, depth, alpha, beta)\n",
    "        self.cache.store_cache(cacheKey, value, depth, alpha, beta)\n",
    "        return value\n",
    "\n",
    "    return cached_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the cache a dedicated class `IterativeAlphaBetaCached` is created inheriting from `IterativeAlphaBeta`.\n",
    "On construction of an object of the `IterativeAlphaBetaCached` class\n",
    "the cache is created\n",
    "and each call of `_evaluate_moves` empties the cache\n",
    "to prevent stale data influencing the analysis.\n",
    "To really use the cache\n",
    "the `_value` function gets the newly created `cache_alpha_beta` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeAlphaBetaCached(IterativeAlphaBeta):\n",
    "\n",
    "    def __init__(self, max_look_ahead_depth: int):\n",
    "        super().__init__(max_look_ahead_depth)\n",
    "        self.cache = AlphaBetaCache()\n",
    "\n",
    "    def _evaluate_moves(self, board: chess.Board):\n",
    "        self.cache.clear()\n",
    "        return super()._evaluate_moves(board)\n",
    "\n",
    "    @cache_alpha_beta\n",
    "    def _value(\n",
    "        self, board: chess.Board, depth: int, alpha: int, beta: int\n",
    "    ) -> int:\n",
    "        return super()._value(board, depth, alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the cache usage should only influence the performance\n",
    "the result of the caching engine should match that of the non-caching engine.\n",
    "This is checked here as seen in previous examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "engine = IterativeAlphaBetaCached(max_look_ahead_depth=2)\n",
    "tree = MinMaxTree.add_tree_to_engine(engine, relative=True)\n",
    "result_iterativeAlphaBetaCached = engine.analyse(middlegame_board)\n",
    "\n",
    "assert result_iterativeAlphaBetaCached == result_iterativeAlphaBeta"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b42f3920614829e661a3e80085f50421aa71f403bff6adf1f40efa6d26183877"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
