{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "with open('style.css') as file:\n",
    "    css = file.read()\n",
    "HTML(css)\n",
    "\n",
    "%run s05_ai_engine.ipynb\n",
    "\n",
    "# Dirty hack to import types from other file for static analysis tools\n",
    "try:\n",
    "    from . import ScoredMove, IterativeAlphaBetaCached, HumanEngine, playGame, middlegame_board, result_iterativeAlphaBetaCached, cache_alpha_beta, NodeType\n",
    "    import chess\n",
    "    import random\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced AI Engine\n",
    "\n",
    "In diesem Abschnitt geht es darum auf dem bisherigen Alpha-Beta Algorithmus und der ersten implementierten Evaluierungsfunktion aufzubauen, um die Spielstärke der Engine weiter zu steigern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Evaluation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst soll die bisher eingesetzte Evaluierungsfunktion, die lediglich die Werte der Figuren betrachtet, durch die komplexere [Simplified Evaluation Function](https://www.chessprogramming.org/Simplified_Evaluation_Function) ersetzt werden. Auf Grund der höheren Komplexität wird diese nun im Gegensatz zu vorher als eine eigene Klasse `SimplifiedEvaluation` implementiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedEvaluation():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch die Simplified Evaluation Function weist den einzelnen Figuren Werte zu. Diese sind sehr ähnlich zu den vorherigen Werten von Capablanca, werden jedoch nun in Centipawns ausgedrückt. Konkret wurde eine Reihe von Bedingungen festgelegt, die auf eigener Erfahrung des Autors basieren. Beispielsweise wird der Läufer nun etwas besser angesehen als der Springer, da dadurch die Engine versucht selbst das Läuferpaar zu behalten und das des Gegners zu nehmen. Das Dictionary `PIECE_VALUES` enthält nachfolgend eine mögliche Wertebelegung, welche die aufgestellen Bedingungen erfüllen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIECE_VALUES = {\n",
    "    chess.PAWN: 100,\n",
    "    chess.KNIGHT: 320,\n",
    "    chess.BISHOP: 330,\n",
    "    chess.ROOK: 500,\n",
    "    chess.QUEEN: 900,\n",
    "    chess.KING: 20000\n",
    "}\n",
    "\n",
    "SimplifiedEvaluation.PIECE_VALUES = PIECE_VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Schachmatt wird erneut mit einem so hohen Wert besetzt, dass dieser auf keinem anderem Wege erreicht werden kann und das Remis wieder mit 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimplifiedEvaluation.VALUE_CHECKMATE = 30000\n",
    "SimplifiedEvaluation.VALUE_DRAW = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die zweite Idee, auf der die Simplified Evaluation Engine aufbaut, sind [Piece Square Tables](https://www.chessprogramming.org/Piece-Square_Tables). Damit die Engine ihre Figuren strategisch sinnvoll platziert, werden gut platzierte Figuren zusätzlich belohnt und schlecht platzierte Figuren bestraft. Dies wird technisch realisiert, indem für jeden Figurentyp jedes Feld auf dem Schachbrett mit einem spezifischen Wert belegt ist. `PAWN_SQUARE_VALUES` zeigt die Werte der Schachfelder als 2 dimensionale 8 x 8 Liste für den weißen Bauern. Der erste Eintrag entspricht dabei der 8. Reihe auf dem Schachfeld und der letze Eintrag der ersten Reihe. Zu sehen ist dabei beispielsweise, dass Bauern auf der siebten Reihe einen hohen Bonus mit 50 erhalten, da diese kurz vor einer Promotion stehen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAWN_SQUARE_VALUES = [\n",
    "    [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [50, 50, 50, 50, 50, 50, 50, 50],\n",
    "    [10, 10, 20, 30, 30, 20, 10, 10],\n",
    "    [ 5,  5, 10, 25, 25, 10,  5,  5],\n",
    "    [ 0,  0,  0, 20, 20,  0,  0,  0],\n",
    "    [ 5, -5,-10,  0,  0,-10, -5,  5],\n",
    "    [ 5, 10, 10,-20,-20, 10, 10,  5],\n",
    "    [ 0,  0,  0,  0,  0,  0,  0,  0]\n",
    "] # yapf: disable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Berechnung später zu vereinfachen können die oben definierte Figurenwerte direkt als Offset mit in die Tabelle geschrieben werden. Dies übernimmt die Hilfsfunktion `add_offset_to_square_values`, welche eine piece square table und einen offset als Parameter entgegennimmt und dann den Offset zu jedem Eintrag der Tabelle hinzuaddiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_offset_to_square_values(square_values: list[list[int]], offset: int):\n",
    "    for row in range(8):\n",
    "        for column in range(8):\n",
    "            square_values[row][column] += offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die `PAWN_SQUARE_VALUES` wird entsprechend als Offset der Figurenwert des Bauern aus dem `PIECE_VALUES` Dictionary hinzugefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_offset_to_square_values(PAWN_SQUARE_VALUES, PIECE_VALUES[chess.PAWN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analog wird dies anschließend auch alle weiteren Tabellen für die jeweiligen Figuren definiert. Teilweise werden für Schwarze und Weiße Figuren verschiedene Tabellen definiert, in dem Fall der `Simplified Evaluation Function` funktionieren die Tabellen jedoch für beide Seiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNIGHT_SQUARE_VALUES = [\n",
    "    [-50,-40,-30,-30,-30,-30,-40,-50],\n",
    "    [-40,-20,  0,  0,  0,  0,-20,-40],\n",
    "    [-30,  0, 10, 15, 15, 10,  0,-30],\n",
    "    [-30,  5, 15, 20, 20, 15,  5,-30],\n",
    "    [-30,  0, 15, 20, 20, 15,  0,-30],\n",
    "    [-30,  5, 10, 15, 15, 10,  5,-30],\n",
    "    [-40,-20,  0,  5,  5,  0,-20,-40],\n",
    "    [-50,-40,-30,-30,-30,-30,-40,-50]\n",
    "]  # yapf: disable\n",
    "\n",
    "add_offset_to_square_values(KNIGHT_SQUARE_VALUES, PIECE_VALUES[chess.KNIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BISHOP_SQUARE_VALUES = [\n",
    "    [-20,-10,-10,-10,-10,-10,-10,-20],\n",
    "    [-10,  0,  0,  0,  0,  0,  0,-10],\n",
    "    [-10,  0,  5, 10, 10,  5,  0,-10],\n",
    "    [-10,  5,  5, 10, 10,  5,  5,-10],\n",
    "    [-10,  0, 10, 10, 10, 10,  0,-10],\n",
    "    [-10, 10, 10, 10, 10, 10, 10,-10],\n",
    "    [-10,  5,  0,  0,  0,  0,  5,-10],\n",
    "    [-20,-10,-10,-10,-10,-10,-10,-20]\n",
    "]  # yapf: disable\n",
    "\n",
    "add_offset_to_square_values(BISHOP_SQUARE_VALUES, PIECE_VALUES[chess.BISHOP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOK_SQUARE_VALUES = [\n",
    "    [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [ 5, 10, 10, 10, 10, 10, 10,  5],\n",
    "    [-5,  0,  0,  0,  0,  0,  0, -5],\n",
    "    [-5,  0,  0,  0,  0,  0,  0, -5],\n",
    "    [-5,  0,  0,  0,  0,  0,  0, -5],\n",
    "    [-5,  0,  0,  0,  0,  0,  0, -5],\n",
    "    [-5,  0,  0,  0,  0,  0,  0, -5],\n",
    "    [ 0,  0,  0,  5,  5,  0,  0,  0]\n",
    "] # yapf: disable\n",
    "\n",
    "add_offset_to_square_values(ROOK_SQUARE_VALUES, PIECE_VALUES[chess.ROOK])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUEEN_SQUARE_VALUES = [\n",
    "    [-20,-10,-10, -5, -5,-10,-10,-20],\n",
    "    [-10,  0,  0,  0,  0,  0,  0,-10],\n",
    "    [-10,  0,  5,  5,  5,  5,  0,-10],\n",
    "    [ -5,  0,  5,  5,  5,  5,  0, -5],\n",
    "    [  0,  0,  5,  5,  5,  5,  0, -5],\n",
    "    [-10,  5,  5,  5,  5,  5,  0,-10],\n",
    "    [-10,  0,  5,  0,  0,  0,  0,-10],\n",
    "    [-20,-10,-10, -5, -5,-10,-10,-20]\n",
    "] # yapf: disable\n",
    "\n",
    "add_offset_to_square_values(QUEEN_SQUARE_VALUES, PIECE_VALUES[chess.QUEEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KING_SQUARE_VALUES = [\n",
    "    [-30,-40,-40,-50,-50,-40,-40,-30],\n",
    "    [-30,-40,-40,-50,-50,-40,-40,-30],\n",
    "    [-30,-40,-40,-50,-50,-40,-40,-30],\n",
    "    [-30,-40,-40,-50,-50,-40,-40,-30],\n",
    "    [-20,-30,-30,-40,-40,-30,-30,-20],\n",
    "    [-10,-20,-20,-20,-20,-20,-20,-10],\n",
    "    [ 20, 20,  0,  0,  0,  0, 20, 20],\n",
    "    [ 20, 30, 10,  0,  0, 10, 30, 20],\n",
    "]# yapf: disable\n",
    "\n",
    "add_offset_to_square_values(KING_SQUARE_VALUES, PIECE_VALUES[chess.KING])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem alle piece square tables definiert wurden, kann nun auch hier analog zu den Figurenwerten ein Dictionary `PIECE_SQUARE_VALUES` erstellt werden, welches jeder Figur die entsprechende Tabelle zuweist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add support for endgame square table (for instance for the king)\n",
    "# Idea: Two tables (beginning and end) -> interpolate (https://www.chessprogramming.org/Piece-Square_Tables#Multiple_Tables)\n",
    "PIECE_SQUARE_VALUES = {\n",
    "    chess.PAWN: PAWN_SQUARE_VALUES,\n",
    "    chess.KNIGHT: KNIGHT_SQUARE_VALUES,\n",
    "    chess.BISHOP: BISHOP_SQUARE_VALUES,\n",
    "    chess.ROOK: ROOK_SQUARE_VALUES,\n",
    "    chess.QUEEN: QUEEN_SQUARE_VALUES,\n",
    "    chess.KING: KING_SQUARE_VALUES\n",
    "}\n",
    "SimplifiedEvaluation.PIECE_SQUARE_VALUES = PIECE_SQUARE_VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion `_get_piece_square_value` nimmt eine Schachfigur `piece` und deren Position mit `file` und `rank` entgegen und gibt den entsprechenden Wert aus der piece square table zurück. Für die Weiße Seite muss die Tabelle zur x-achse gespiegelt werden, entsprechend wird dort mit `7 - rank` drauf zugegriffen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_piece_square_value(self, piece: chess.Piece, file: int, rank: int):\n",
    "    if piece.color == chess.WHITE:\n",
    "        return self.PIECE_SQUARE_VALUES[piece.piece_type][7 - rank][file]\n",
    "    else:\n",
    "        return self.PIECE_SQUARE_VALUES[piece.piece_type][rank][file]\n",
    "\n",
    "\n",
    "SimplifiedEvaluation._get_piece_square_value = _get_piece_square_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da häufig über Schachfelder iteriert werden muss, wird zusätzlich noch eine Funktion `_get_square_value` implementiert, welche das Board `board` und ein Schachfeld `square` entgegennimmt und daraus die Figur, file und rank berechnen und an die zuvor definierte Methode `_get_square_value` weiterleitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_square_value(self, board: chess.Board, square: chess.Square):\n",
    "    piece = board.piece_at(square)\n",
    "    file = chess.square_file(square)\n",
    "    rank = chess.square_rank(square)\n",
    "    return self._get_piece_square_value(piece, file, rank)\n",
    "\n",
    "\n",
    "SimplifiedEvaluation._get_square_value = _get_square_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun kann eine absolute Heuristik `absolute_heuristic` definiert. Sie nimmt als Parameter ein Schachbrett `board` entgegen und gibt die aktuelle Bewertung aus Sicht des Spielers am Zug zurück. Dazu iteriert sie zunächst über alle besetzen Felder des Spielers am Zug und summiert die Werte für diese Felder. Anschließend werden die Werte der gegnerischen besetzen Felder abgezogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_heuristic(self, board: chess.Board) -> int:\n",
    "    \"\"\"Calculate the value of all pieces on the board\"\"\"\n",
    "    score = 0\n",
    "\n",
    "    for square in chess.scan_reversed(board.occupied_co[board.turn]):\n",
    "        score += self._get_square_value(board, square)\n",
    "\n",
    "    for square in chess.scan_reversed(board.occupied_co[not board.turn]):\n",
    "        score -= self._get_square_value(board, square)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "SimplifiedEvaluation.absolute_heuristic = absolute_heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch die bereits bekannte `evaluate` Funktion wird der `SimplifiedEvaluation` Klasse hinzugefügt, da diese die benötigten Werte `VALUE_CHECKMATE` und `VALUE_DRAW` hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(self, board: chess.Board) -> int:\n",
    "    if board.is_checkmate():\n",
    "        return -self.VALUE_CHECKMATE\n",
    "    if board.is_draw():\n",
    "        return self.VALUE_DRAW\n",
    "    return None\n",
    "\n",
    "\n",
    "SimplifiedEvaluation.evaluate = evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `SimplifiedEvaluationEngine` Engine integriert die zuvor definierte `SimplifiedEvaluation` Klasse. Gegenüber der vorherigen Implementierung, muss eine Instanz der  `SimplifiedEvaluation` Klasse im Konstruktor erzeugt werden und alle ausgegliederte Funktionalität wie `VALUE_CHECKMATE`, `absolute_heuristic` und `evaluate` über diese Instanz aufgerufen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedEvaluationEngine(IterativeAlphaBetaCached):\n",
    "\n",
    "    def __init__(self, max_look_ahead_depth: int):\n",
    "        super().__init__(max_look_ahead_depth)\n",
    "        self.evaluator = SimplifiedEvaluation()\n",
    "\n",
    "    def _evaluate_move(self, board: chess.Board, move: chess.Move, depth: int):\n",
    "        board.push(move)\n",
    "        score = self._value(\n",
    "            board,\n",
    "            depth,\n",
    "            -self.evaluator.VALUE_CHECKMATE,\n",
    "            self.evaluator.VALUE_CHECKMATE\n",
    "        )\n",
    "        score *= self.PLAYER_MULTIPLIER[board.turn]\n",
    "        board.pop()\n",
    "        return ScoredMove(score=score, move=move)\n",
    "\n",
    "    @cache_alpha_beta\n",
    "    def _value(\n",
    "        self, board: chess.Board, depth: int, alpha: int, beta: int\n",
    "    ) -> int:\n",
    "        if (score := self.evaluator.evaluate(board)) is not None:\n",
    "            return score\n",
    "        if depth == 0:\n",
    "            return self.evaluator.absolute_heuristic(board)\n",
    "\n",
    "        for move in board.legal_moves:\n",
    "            board.push(move)\n",
    "            value = -1 * self._value(board, depth - 1, -beta, -alpha)\n",
    "            board.pop()\n",
    "\n",
    "            if value >= beta:\n",
    "                return value\n",
    "            alpha = max(alpha, value)\n",
    "\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `SimplifiedEvaluationEngine` kann wie gewohnt getestet werden. Ein Vergleich mit den vorherigen Ergebnissen ergibt an dieser Stelle jedoch keinen Sinn, da die neue Evaluierunsfunktion zu völlig anderen Ergebnissen kommen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MinMaxTree\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "engine = SimplifiedEvaluationEngine(max_look_ahead_depth=3)\n",
    "tree = MinMaxTree.add_tree_to_engine(engine, relative=True)\n",
    "result_SimplifiedEvaluationEngine = engine.analyse(middlegame_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die jupyter Notebook extension `line_profiler` definiert ein magic command `lprun` mit dem die Performance einer Anweisung analysiert werden kann. In dem Fall ist es von Interesse, welche Anweisungen bei der Analyse eines Brettes mit `engine.analyse(middlegame_board)` am häufigsten aufgerufen werden und am meisten Zeit benötigen. Diese Informationen werden von dem Line Profiler für eine spezifierte Funktion ausgegeben. Am interessanten ist dabei die rekursiv aufgerufene Funktion `_value`, welche es zu optimieren gilt. Der Zugriff erfolgt etwas komplexer mit `SimplifiedEvaluationEngine._value.__wrapped__`, da die Funktion einen decorator hat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "random.seed(42)\n",
    "\n",
    "engine = SimplifiedEvaluationEngine(max_look_ahead_depth=3)\n",
    "%lprun -f SimplifiedEvaluationEngine._value.__wrapped__ engine.analyse(middlegame_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Auswertung ergibt, dass alle Aufrufe der absoluten Heuristik mit `self.evaluator.absolute_heuristic(board)` ca. 50% der Gesamt Laufzeit ausmachen. An zweiter Stelle und dritter Stelle mit ca. 15% liegt die Evaluierung ` self.evaluator.evaluate(board)` und der Aufruf von `board.push(move)`. Hier sind zunächst keine direkten Optimierungen möglich, da hierfür die Implementierung der `python-chess` Bibliothek optimiert werden müsste. \n",
    "Bei der Heuristik dagegen ist es möglich zu optimieren, indem die Auswertung inkrementell erfolgt. Dazu wird eine neue Klasse `SimplifiedIncrementalEvaluation`, welche `SimplifiedEvaluation` erweitert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedIncrementalEvaluation(SimplifiedEvaluation):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst wird eine `init` Methode definiert, welche ein Schachbrett `board` als Parameter entgegennimmt. Diese Funktioniert initialisiert eine Liste an scores. Zu diesem Zeitpunkt sind keine vorherigen Informationen bekannt, weswegen der erste score mit der absoluten Heuristik berechnet werden muss. Die `init` Funktion wird entsprechend am Anfang einer jeden Analyse aufgerufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(self, board: chess.Board):\n",
    "    self.scores = [self.absolute_heuristic(board)]\n",
    "\n",
    "\n",
    "SimplifiedIncrementalEvaluation.init = init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun soll eine `push` Methode definiert werden, welche immer dann aufgerufen werden soll, wenn ein Spielzug innerhalb der Analyse, d.h. innerhalb der rekursiven `_value` Aufrufe, hinzugefügt wird. Die Aufgabe der Methode ist es basierend auf der Bewertung der vorherigen Stellung, performant eine neue Bewertung für die neue Stellung zu berechnen. \n",
    "Die Änderung der Bewertung durch den Zug hängt unter anderem davon ab, welche Figur gezogen ist und ob möglicherweise eine generische Figur dabei geschlagen wurde. Diese Informationen werden nicht in `chess.Move` direkt gespeichert, sondern lassen sich nur mit zusätzlichen Information aus dem Board ableiten. Zusätzlich ist auch die Betrachung von einigen Randfällen nötig wie das Schlagen en passant oder die Promotion. Daher wurde sich entschieden eine Klasse als Abstraktion einzuführen, welche die Informationen berechnet und gebündelt speichert. \n",
    "\n",
    "Zunächst wird eine Klasse `PostionedPiece` eingeführt, welche neben der Figur vom Typ `chess.Piece` auch dessen aktuelle Position speichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostionedPiece:\n",
    "\n",
    "    def __init__(self, piece: chess.Piece, file: int, rank: int):\n",
    "        self.piece = piece\n",
    "        self.file = file\n",
    "        self.rank = rank\n",
    "        self.square = chess.square(file_index=file, rank_index=rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die eigentliche Klasse zur Abstraktion ist nun die `DetailedMove` Klasse, welche im Konstruktor das aktuelle board und den move entgegennimmt. Im Konstruktor werden dann die verschiedenen benötigten Informationen abgespeichert. Dabei wird zunächst die ziehende Figur auf ihrem ursprünglichen Feld als `PostionedPiece` in `self.movedPiece` abgespeichert. Anschließend wird analog die ziehende Funktion auf ihrem Zielfeld in `self.placedPiece` abgespeichert. Hierbei muss beachtet werden, dass durch eine Promotion die Figur sich gegebenfalls geändert hat. Zuletzt wird noch die geschlagende Figur, sofern es eine gibt, in `self.capturedPiece` abgespeichert. Hierbei muss der spezielle Fall betrachtet werden, dass es sich um ein Schlagen en passant handelt. In diesem Fall ergibt sich die Position der schlagenden Figur aus der Reihe von `movedPiece`, aber der Spalte von `placedPiece`.\n",
    "Außerdem wird eine Funktion `hasCapture` definiert, um zu überprüfen, ob mit diesem Zug eine Figur geschlagen wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetailedMove:\n",
    "\n",
    "    def __init__(self, board: chess.Board, move: chess.Move):\n",
    "        self.move = move\n",
    "\n",
    "        self.movedPiece = PostionedPiece(\n",
    "            piece=board.piece_at(move.from_square),\n",
    "            file=chess.square_file(move.from_square),\n",
    "            rank=chess.square_rank(move.from_square)\n",
    "        )\n",
    "\n",
    "        if move.promotion:\n",
    "            self.placedPiece = PostionedPiece(\n",
    "                piece=chess.Piece(move.promotion, self.movedPiece.piece.color),\n",
    "                file=chess.square_file(move.to_square),\n",
    "                rank=chess.square_rank(move.to_square)\n",
    "            )\n",
    "        else:\n",
    "            self.placedPiece = PostionedPiece(\n",
    "                piece=self.movedPiece.piece,\n",
    "                file=chess.square_file(move.to_square),\n",
    "                rank=chess.square_rank(move.to_square)\n",
    "            )\n",
    "\n",
    "        if board.is_en_passant(move):\n",
    "            self.capturedPiece = PostionedPiece(\n",
    "                piece=chess.Piece(chess.PAWN, not board.turn),\n",
    "                file=self.movedPiece.file,\n",
    "                rank=self.placedPiece.rank\n",
    "            )\n",
    "        elif (piece := board.piece_at(move.to_square)) is not None:\n",
    "            self.capturedPiece = PostionedPiece(\n",
    "                piece=piece,\n",
    "                file=self.placedPiece.file,\n",
    "                rank=self.placedPiece.rank\n",
    "            )\n",
    "        else:\n",
    "            self.capturedPiece = None\n",
    "\n",
    "    def hasCapture(self):\n",
    "        return self.capturedPiece is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Hilfe der definierten Klassen, kann nun die `push` Methode implementiert werden. Diese nimmt als Parameter einen DetailedMove `move`. Als Ausgangspunkt wird der letze score Eintrag genutzt. Dann wird der Wert von `move.movedPiece` abgezogen und der von `move.placedPiece` hinzuaddiert. Sollte mit dem Zug eine Figur geschlagen werden, wird auch dessen Wert zum score hinzuaddiert. Der neue score wird dann negiert an die Liste `self.scores` angefügt, da die Bewertung ja immmer aus der Perspektive des Spielers am Zug ist und das Vorzeichen daher immer wechseln muss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push(self, move: DetailedMove):\n",
    "    score = self.scores[-1]\n",
    "\n",
    "    score -= self._get_piece_square_value(\n",
    "        move.movedPiece.piece, move.movedPiece.file, move.movedPiece.rank\n",
    "    )\n",
    "\n",
    "    score += self._get_piece_square_value(\n",
    "        move.placedPiece.piece, move.placedPiece.file, move.placedPiece.rank\n",
    "    )\n",
    "\n",
    "    if move.hasCapture():\n",
    "        score += self._get_piece_square_value(\n",
    "            move.capturedPiece.piece,\n",
    "            move.capturedPiece.file,\n",
    "            move.capturedPiece.rank\n",
    "        )\n",
    "\n",
    "    self.scores.append(-1 * score)\n",
    "\n",
    "\n",
    "SimplifiedIncrementalEvaluation.push = push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neben der `push` Methode gibt es entsprechend dann auch eine `pop` Methode, die immer aufgerufen werden soll, wenn ein Zug wieder rückgängig gemacht worden ist. Die Methode nimmt keine Parameter entgegen und entfernt lediglich den jeweils letzen Eintrag der `self.scores` Liste. Diese kurze und performante Implementierung wurde dadurch ermöglicht, dass eben `push` jeden neuen score in der Liste ablegt und nicht den alten überschreibt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop(self):\n",
    "    self.scores.pop()\n",
    "\n",
    "\n",
    "SimplifiedIncrementalEvaluation.pop = pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuletzt wird noch eine Methode `getScore` ohne Parameter definiert, welche den aktuellen score, d.h. den letzen Eintrag in der Liste, zurückgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(self):\n",
    "    return self.scores[-1]\n",
    "\n",
    "\n",
    "SimplifiedIncrementalEvaluation.getScore = getScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun kann auch eine Engine mit der inkrementellen simplified evaluation Funktion erstellt werden. Wie zuvor auch sind nur kleine Anpassungen nötig. Im Konstruktor muss selbstverständlich der evaluation nun mit einem Objekt der Klasse `SimplifiedIncrementalEvaluation` initialisiert werden. Für die `_evaluate_move` Methode wurde nur die Zeile `self.evaluator.init(board)` hinzugefügt. Diese dient dazu das Board einmal zu Beginn mit der absoluten Heuristik auszuwerten, sodass dann anschließend folgende Positionen inkrementell berechnet werden können. In der `value` Methode muss immer vor dem pushen eines neues Zuges auf das Board `self.evaluator.push(DetailedMove(board, move))` und beim entfernen eines Zuges `self.evaluator.pop()` aufgerufen werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedIncrementalEvaluationEngine(SimplifiedEvaluationEngine):\n",
    "\n",
    "    def __init__(self, max_look_ahead_depth: int):\n",
    "        super().__init__(max_look_ahead_depth)\n",
    "        self.evaluator = SimplifiedIncrementalEvaluation()\n",
    "\n",
    "    def _evaluate_move(self, board: chess.Board, move: chess.Move, depth: int):\n",
    "        board.push(move)\n",
    "        self.evaluator.init(board)\n",
    "\n",
    "        score = self._value(\n",
    "            board,\n",
    "            depth,\n",
    "            -self.evaluator.VALUE_CHECKMATE,\n",
    "            self.evaluator.VALUE_CHECKMATE\n",
    "        )\n",
    "        score *= self.PLAYER_MULTIPLIER[board.turn]\n",
    "        board.pop()\n",
    "        return ScoredMove(score=score, move=move)\n",
    "\n",
    "    @cache_alpha_beta\n",
    "    def _value(\n",
    "        self, board: chess.Board, depth: int, alpha: int, beta: int\n",
    "    ) -> int:\n",
    "        if score := self._evaluate(board):\n",
    "            return score\n",
    "        if depth == 0:\n",
    "            return self.evaluator.getScore()\n",
    "\n",
    "        for move in board.legal_moves:\n",
    "            detailedMove = DetailedMove(board, move)\n",
    "            self.evaluator.push(detailedMove)\n",
    "            board.push(move)\n",
    "\n",
    "            value = -1 * self._value(board, depth - 1, -beta, -alpha)\n",
    "            self.evaluator.pop()\n",
    "            board.pop()\n",
    "\n",
    "            if value >= beta:\n",
    "                return value\n",
    "            alpha = max(alpha, value)\n",
    "\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die definierte Engine kann getestet werden und in diesem Fall auch wieder das Ergebnis mit dem vorherigen verglichen werden, da die inkrementelle Bewertung die Ergebnisse nicht beeinflussen sollte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "engine = SimplifiedIncrementalEvaluationEngine(max_look_ahead_depth=3)\n",
    "tree = MinMaxTree.add_tree_to_engine(engine, relative=True)\n",
    "result_SimplifiedIncrementalEvaluationEngine = engine.analyse(middlegame_board)\n",
    "\n",
    "assert result_SimplifiedIncrementalEvaluationEngine == result_SimplifiedEvaluationEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wieder kann mit dem Line Profiler die `_value` Methode analysiert werden. Zu sehen ist, dass die eingefügten Änderungen zusammen nur noch ca. 20% der Gesamtzeit ausmachen. Dies stellt eine deutliche Verbesserung gegenüber den vorherigen Implementierung mit 50% dar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "random.seed(42)\n",
    "\n",
    "engine = SimplifiedIncrementalEvaluationEngine(max_look_ahead_depth=3)\n",
    "%lprun -f SimplifiedIncrementalEvaluationEngine._value.__wrapped__ engine.analyse(middlegame_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiescence Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein aktuelles Problem der Engine ist, dass sie immer bei einer fixen Tiefe aufhört zu analysieren unabhängig von der Stellung. Dies kann dazu führen, dass die Engine in zum Beispiel einem Schlagabtausch die Suche beendet und somit die Stellung völlig falsch interpretiert wird. Oder die Engine versucht eine für sie ungünstige Situation durch z.B. das Geben von Schach soweit hinauszugöern, dass diese Situation in der limitierten Suchtiefe nicht mehr auftreten kann. Hierbei spricht man auch von dem [Horizon Effekt](https://www.chessprogramming.org/Horizon_Effect). \n",
    "Um dies zu vermeiden, ist die Idee, nur ruhige Stellungen mit der Heuristik zu analysieren. Als ruhige Stellung zählen solche in denen keine Figur mehr geschlagen werden kann und je nach Implementierung auch kein Schach gegeben werden kann. In den anderen Fällen wird eine eingeschränkte Suche gemacht, die genau solche Züge noch weiter analysiert. Dies wird [quiescence search](https://www.chessprogramming.org/Quiescence_Search) genannt.\n",
    "Dazu wird nun eine neue Klasse `QuiescenceEngine`, welche die vorherige Engine `SimplifiedIncrementalEvaluationEngine` erweitert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuiescenceEngine(SimplifiedIncrementalEvaluationEngine):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An der `_value` Funktion muss lediglich eine Anpassung gemacht werden. Im dem Fall, dass die Tiefe 0 ist wird nun die Funktion `_quiescence` aufgerufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache_alpha_beta\n",
    "def _value(self, board: chess.Board, depth: int, alpha: int, beta: int) -> int:\n",
    "    if score := self._evaluate(board):\n",
    "        return score\n",
    "    if depth == 0:\n",
    "        return self._quiescence(board, alpha, beta)\n",
    "\n",
    "    for move in board.legal_moves:\n",
    "        detailedMove = DetailedMove(board, move)\n",
    "\n",
    "        self.evaluator.push(detailedMove)\n",
    "        board.push(move)\n",
    "        value = -1 * self._value(board, depth - 1, -beta, -alpha)\n",
    "        board.pop()\n",
    "        self.evaluator.pop()\n",
    "\n",
    "        if value >= beta:\n",
    "            return value\n",
    "        alpha = max(alpha, value)\n",
    "\n",
    "    return alpha\n",
    "\n",
    "\n",
    "QuiescenceEngine._value = _value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `_quiesce` Methode nimmt als Parameter ein `chess.Board` board, einen `int` alpha und einen `int` beta und gibt genauso wie die `_value` Funktion den score der aktuellen Position zurück. Zunächst wird ein Standing Pat berechnet, dabei handelt es sich um die statische Evaluation der aktuellen Stellung. Ist diese höher als beta, kann direkt beta zurückgegeben werden. Ansonsten wird `alpha` angehoben, sofern der Wert größer ist. `alpha` wird auch mindestens von der Funktion zurückgegeben, sodass gilt `stand_path <= alpha <= _quiesce(board, alpha, beta) <= beta`. \n",
    "\n",
    "Andernfalls ist der Algorithmus vergleichbar zu dem der `_value` Funktion. Es gibt jedoch zwei wesentliche Unterschiede. Einerseits werden hier nicht alle möglichen Züge betrachtet, sondern nur solche, die Figuren schlagen. Der andere Unterschied ist, dass bevor die restliche Implementierung von NegaMax folgt, noch einige Optimierungen erfolgen. \n",
    "Diese sind notwendig, denn ein großer Teil der Suchzeit nimmt die quiescence search ein, da in nahezu jeder Position einige Schlagabtäusche möglich sind und die Anzahl der Knoten damit massiv ansteigt. \n",
    "\n",
    "Konkret werden Züge nicht analysiert sofern keine Promotion vorliegt und DeltaPruning erfolgt oder die Static Exchange Evaluation kleiner 0 ist. Beide Optimierungen werden nachfolgend noch geklärt. Andenfalls wird wie bereits aus dem NegaMax Algorithmus bekannt fortgefahren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _quiescence(self, board: chess.Board, alpha: int, beta: int) -> int:\n",
    "    stand_pat = self.evaluator.getScore()\n",
    "\n",
    "    if stand_pat >= beta:\n",
    "        return beta\n",
    "    alpha = max(alpha, stand_pat)\n",
    "\n",
    "    for move in board.generate_legal_captures():\n",
    "        detailedMove = DetailedMove(board, move)\n",
    "\n",
    "        if move.promotion is None:\n",
    "            if self._canDeltaPrune(stand_pat, alpha, detailedMove):\n",
    "                continue\n",
    "            if self._seeCapture(board, detailedMove) < 0:\n",
    "                continue\n",
    "\n",
    "        board.push(move)\n",
    "        self.evaluator.push(detailedMove)\n",
    "\n",
    "        value = -1 * self._quiescence(board, -beta, -alpha)\n",
    "\n",
    "        self.evaluator.pop()\n",
    "        board.pop()\n",
    "\n",
    "        if value >= beta:\n",
    "            return value\n",
    "        alpha = max(alpha, value)\n",
    "    return alpha\n",
    "\n",
    "\n",
    "QuiescenceEngine._quiescence = _quiescence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Idee von Delta Pruning ist, dass es einige Stellungen gibt in denen der Spieler bereits soweit zurückliegt, dass auch potentielle gute Züge nicht mehr helfen können. Ein Beispiel hierfür ist, wenn der Spieler eine Dame zurückliegt, dann ändert das Schlagen eines Bauerns oder einer Leichtfigur nichts daran, dass er immer noch zurückliegt. \n",
    "Die Methode `_canDeltaPrune` überprüft genau dies und nimmt den standing pat, alpha und den zu testenden move als Parameter entgegen. Kann der Zug durch delta Pruning ignoriert werden, gibt die Methode `True` zurück, andernfalls `False`. \n",
    "Zunächst berechnet sie zum aktuellen Stand Pat den Wert der zu schlagenden Figur hinzu, sowie einen potentiellen Stellungsvorteil von 2 Bauern, daher 200 Centipawns. Hierbei handelt es sich gewissermaßen, um eine sehr optimistische Schätzung für den Spieler. Denn dieser bekommt einen Positionsvorteil zugesprochen und es wird davon ausgegangen, dass er die Figur einfach Schlagen kann ohne zurückgeschlagen zu werden. Liegt dieser optmistische Wert trotzdem unter `alpha`, so lohnen sich weitere Untersuchungen nicht. In diesem Fall gibt die Methode `True` zurück, andernfalls `False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _canDeltaPrune(\n",
    "    self, stand_pat: int, alpha: int, detailedMove: DetailedMove\n",
    "):\n",
    "    # TODO: Don't do this in endgames\n",
    "    pieceValue = self.evaluator.PIECE_VALUES[\n",
    "        detailedMove.capturedPiece.piece.piece_type]\n",
    "    bestAlpha = stand_pat + pieceValue + 200\n",
    "    return bestAlpha < alpha\n",
    "\n",
    "\n",
    "QuiescenceEngine._canDeltaPrune = _canDeltaPrune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die zweite Optimierung `Static Exchange Evaluation` analysiert den potentiellen Schlagabtausch zwischen den Spielern. Dabei wird angenommen, dass beide Spieler jeweils mit ihrer geringwertigsten Figur die Figur des Gegners schlagen, sofern am Ende des Schlagabtausches einen Vorteil für den jeweiligen Spieler entsteht. \n",
    "Die Methode `_seeCapture` nimmt als Parameter das aktuelle board und den Zug entgegen und gibt den Wert des Schlagabtausches zurück. Ein positver Wert bedeutet dabei, dass der Spieler am Zug durch den Schlagabtausch vorraussichtlich Material gewinnt und ein negativer, dass dieser vorraussichtlich Material verliert. Daher werden die Züge, welche einen Wert kleiner 0 haben, in der `_quiescence` Methode übersprungen. \n",
    "Die Methode pusht zunächst den übergeben Zug, berechnet den Static Exchange Evaluation score, entfernt den Zug wieder und gibt den score zurück. Die Berechnung des Scores ist grundsätzlich rekursiv implementiert. Dabei wird immer der Static Exchange Evaluation score des verbleibendenen Schlagabtausches von dem Wert der eben geschlagenden Figur abgezogen. Die Rekursion findet dann allerdings in der Methode `_see` statt, da für den verbleibdenen Schlagabtausch die Züge erst berechnet werden müssen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _seeCapture(self, board: chess.Board, detailedMove: DetailedMove):\n",
    "    board.push(detailedMove.move)\n",
    "    capturedPiece = detailedMove.capturedPiece\n",
    "    value = self.evaluator.PIECE_VALUES[\n",
    "        capturedPiece.piece.piece_type\n",
    "    ] - self._see(board, capturedPiece.square)\n",
    "    board.pop()\n",
    "    return value\n",
    "\n",
    "\n",
    "QuiescenceEngine._seeCapture = _seeCapture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `_see` Methode bekommt ebenfalls das aktuelle Board als Parameter, sowie nun das Schachfeld auf dem der Schlagabtausch stattfindet und gibt den Static Exchange Evaluation Score zurück. Zunächst werden alle Angreifer des Felder mit der `attackers` Methode berechnet. Dabei müssen pinned Figuren ignoriert werden mit der `is_pinned` Methode. Wenn es keinen Attacker gibt, wird 0 zurückgegeben. Andernfalls wird die Figur mit dem geringsten Wert ausgewählt und der entsprechende Zug ausgeführt. Dann wir der score wieder rekursiv berechnet, indem der Score des verbleibenden Schlagabtausches  von der eben geschlagenen Figur abgezogen wird. Ist der score niedriger als 0, wird er auf 0 gesetzt. Der Grund hierfür ist, dass der Schlagabtausch vom Spieler nur durchgeführt werden, wenn dies für ihn vorteilhaft ist. Anschließend wird der eben gespielte Zug wieder entfern und der score zurückgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _see(self, board: chess.Board, square: chess.Square):\n",
    "    attackers_squares = [\n",
    "        square for square in board.attackers(board.turn, square)\n",
    "        if not board.is_pinned(board.turn, square)\n",
    "    ]\n",
    "    if not attackers_squares:\n",
    "        return 0\n",
    "\n",
    "    attacker_square = min(\n",
    "        attackers_squares,\n",
    "        key=lambda attackers_square: board.piece_type_at(attackers_square)\n",
    "    )\n",
    "    capturedPiece = board.piece_type_at(square)\n",
    "\n",
    "    board.push(chess.Move(from_square=attacker_square, to_square=square))\n",
    "    value = max(\n",
    "        0,\n",
    "        self.evaluator.PIECE_VALUES[capturedPiece] - self._see(board, square)\n",
    "    )\n",
    "    board.pop()\n",
    "    return value\n",
    "\n",
    "\n",
    "QuiescenceEngine._see = _see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion wird anschließend getestet mit einigen Beispielen. Im ersten Test ist einer der Angreifer gepinned und kann daher nicht schlagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = chess.Board(\"6k1/6b1/8/4p3/3P4/8/8/1K4R1 w - - 0 1\")\n",
    "IPython.display.display(board)\n",
    "engine = QuiescenceEngine(max_look_ahead_depth=3)\n",
    "result = engine._see(board, chess.E5)\n",
    "assert result == 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im zweiten Beispiel sind nicht alle Schlagabtäusche sinnvoll, daher soll hier getestet werden, ob dies entsprechend bei der Bewertung berücksichtigt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = chess.Board(\"6k1/6b1/5p2/4q3/3P4/8/8/1K2Q3 w - - 0 1\")\n",
    "IPython.display.display(board)\n",
    "engine = QuiescenceEngine(max_look_ahead_depth=3)\n",
    "result = engine._see(board, chess.E5)\n",
    "assert result == 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "board = chess.Board(\"8/1R6/4Q3/8/3k1B2/5R2/P1P3PP/6K1 w - - 7 95\")\n",
    "engine = QuiescenceEngine(max_look_ahead_depth=2)\n",
    "engine.analyse(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die eben definierte Engine kann nun einmal komplett getestet werden auf dem üblichen `middlegame_board`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "engine = QuiescenceEngine(max_look_ahead_depth=3)\n",
    "engine.analyse(middlegame_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "engine = QuiescenceEngine(max_look_ahead_depth=3)\n",
    "tree = MinMaxTree.add_tree_to_engine(engine, relative=True)\n",
    "engine.analyse(middlegame_board)\n",
    "\n",
    "tree.count(quiesce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f QuiescenceEngine._quiescence  engine.analyse(middlegame_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f QuiescenceEngine._see  engine.analyse(middlegame_board)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b42f3920614829e661a3e80085f50421aa71f403bff6adf1f40efa6d26183877"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
