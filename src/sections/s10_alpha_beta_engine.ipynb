{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no-python-export",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open('style.css') as file:\n",
    "    css = file.read()\n",
    "HTML(css)\n",
    "\n",
    "# Autload python modules by default\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Convert notebooks to python, so they can be loaded effiently\n",
    "from utils.jupyer_loader import JupyerLoader\n",
    "\n",
    "loader = JupyerLoader()\n",
    "loader.load_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "# AlphaBeta Pruning Engine\n",
    "\n",
    "The previous example makes clear that the primary goal to increase the search depth must be a reduction of the nodes. The `MiniMax algorithm` is a depth-first search where the paths have to be evaluated completely one after the other. If it is the maximizing player's turn, i.e. white, the first evaluation of the path gives the minimum value white can reach. Each further path must exceed this value so that it is ultimately played by white. Similarly, for black on the move, each further path must undercut the previous value for it to be played by black. \n",
    "\n",
    "The `AlphaBeta Pruning Algorithm` builds on this idea and introduces two additional parameters `alpha` and `beta` for the `_value` function. `alpha` is the value that the current position has at least and beta is the value that the position has at most. Therefore `alpha <= _value(board, depth, alpha, beta) <= beta` holds.\n",
    "\n",
    "First, a new class `AlphaBetaEngine` is defined again, which inherits from `MiniMaxEngine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converted_notebooks.s09_minimax_engine import MiniMaxEngine\n",
    "\n",
    "\n",
    "class AlphaBetaEngine(MiniMaxEngine):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "The `_value` function has the same interface as before except for the two new parameters `alpha` and `beta`. The termination conditions of the recursive function are also the same. \n",
    "\n",
    "For the maximizing player, hence the white player, `alpha` stores the current best score that can be achieved in that position. For each child node, alpha is therefore incremented with the statement `alpha = max(alpha, value)` if its value is higher. However, if `alpha` or the score of a child node is greater than `beta`, the search can be terminated prematurely. This is called a `beta cutoff`. The reason for this is that with `beta` Black could already achieve a better score for himself in another position and thus will not let White get into the current situation at all. Thus it is of no use to White to analyze the further moves. \n",
    "\n",
    "The same applies to the minimizing player. His currently best score is stored in `beta` and always lowered with the instruction `beta = min(beta, value)` if a child node has a low and therefore better value for black. If `beta` or the value of the child node is below `alpha`, the search can be aborted. This is called an `alpha cutoff`. Here, too, White had already found a better move for himself one level higher with `alpha` and will therefore not let Black get into this position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "\n",
    "\n",
    "def _value(self, board: chess.Board, depth: int, alpha: int, beta: int) -> int:\n",
    "    if score := self.evaluator.evaluate(board):\n",
    "        return self.PLAYER_MULTIPLIER[board.turn] * score\n",
    "    if depth == 0:\n",
    "        return self.PLAYER_MULTIPLIER[board.turn\n",
    "                                      ] * self.evaluator.heuristic(board)\n",
    "\n",
    "    if board.turn is chess.WHITE:\n",
    "        for move in board.legal_moves:\n",
    "            board.push(move)\n",
    "            value = self._value(board, depth - 1, alpha, beta)\n",
    "            board.pop()\n",
    "            if value >= beta:\n",
    "                return value\n",
    "            alpha = max(alpha, value)\n",
    "\n",
    "        return alpha\n",
    "    else:\n",
    "        for move in board.legal_moves:\n",
    "            board.push(move)\n",
    "            value = self._value(board, depth - 1, alpha, beta)\n",
    "            board.pop()\n",
    "            if alpha >= value:\n",
    "                return value\n",
    "            beta = min(beta, value)\n",
    "\n",
    "        return beta\n",
    "\n",
    "\n",
    "AlphaBetaEngine._value = _value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "Finally, the `_evaluate_move` method must be adapted. This is identical to the implementation of the `MiniMaxEngine` with exception of the `_value` call. There you have to pass an initial value for `alpha` and `beta`. Since no move has been played yet, White can in any case achieve the worst possible result, he is set to mate. Accordingly `alpha` is initialized with `-self.VALUE_CHECKMATE`. The best possible result for white is to set mate himself, accordingly `beta` is initialized with `self.VALUE_CHECKMATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converted_notebooks.s04_engine_interface import ScoredMove\n",
    "\n",
    "\n",
    "def _evaluate_move(self, board: chess.Board, move: chess.Move):\n",
    "    board.push(move)\n",
    "    score = self._value(\n",
    "        board,\n",
    "        self.look_ahead_depth,\n",
    "        -self.evaluator.value_checkmate,\n",
    "        self.evaluator.value_checkmate\n",
    "    )\n",
    "    board.pop()\n",
    "    return ScoredMove(score=score, move=move)\n",
    "\n",
    "\n",
    "AlphaBetaEngine._evaluate_move = _evaluate_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "Now the `AlphaBetaEngine` can evaluate the same constructed position `sample_minimax_board`. You can see in the graph that some nodes are marked with a question mark. These are the nodes that in this case did not have to be evaluated, because the result of the parent node was already defined before due to alpha and beta cutoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils.min_max_tree\n",
    "from converted_notebooks.s08_evaluation import standard_evaluator\n",
    "from converted_notebooks.s09_minimax_engine import sample_minimax_board\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "engine = AlphaBetaEngine(evaluator=standard_evaluator, look_ahead_depth=2)\n",
    "# engine = AlphaBetaEngine(evaluator=standard_evaluator, look_ahead_depth=3)\n",
    "tree = utils.min_max_tree.add_tree_to_engine(engine)\n",
    "print(engine.analyse(sample_minimax_board))\n",
    "tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "For the second position 'middlegame_board', the number of nodes can again be calculated for depths two and three. At a depth of two, with 7'459 only about 10% of the previous nodes have to be examined, 62'660 paths were pruned. At a depth of three, with 10,7628 nodes only about 5% of the previous nodes have to be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils.min_max_tree\n",
    "from converted_notebooks.s08_evaluation import standard_evaluator\n",
    "from converted_notebooks.s09_minimax_engine import middlegame_board, result_minimax\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "engine = AlphaBetaEngine(evaluator=standard_evaluator, look_ahead_depth=2)\n",
    "# engine = AlphaBetaEngine(evaluator=standard_evaluator, look_ahead_depth=3)\n",
    "tree = utils.min_max_tree.add_tree_to_engine(engine)\n",
    "result_alphabeta = engine.analyse(middlegame_board)\n",
    "tree.count()\n",
    "\n",
    "assert result_minimax == result_alphabeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "From the operation of the algorithm, it is obvious that it is advantageous if the best path is evaluated first. In the best case, it is possible that the `x` nodes considered at `MiniMax` decrease to `sqrt(x)` when [Alpha Beta Pruning](https://www.chessprogramming.org/Alpha-Beta) is applied. If, on the other hand, the moves are sorted the other way around, so that the worst path is started with, no pruning is possible at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "## NegaMax Algorithmus \n",
    "\n",
    "The `NegaMax algorithm` does not lead to a direct improvement of the engine, but simplifies the code of the `MiniMax algorithm` and all algorithms based on it. The basic idea here is that the evaluation of each node is done from the perspective of the player on the move. Thus both players are maximizing and the previous case distinction is no longer necessary. \n",
    "\n",
    "For the previous implementation of `_value` for the `AlphaBeta Pruning Algorithm`, this first of all changes the return values of the termination conditions. Since the value is now from the perspective of the player on the move and the functions `_evaluate` and `_absolute_heuristic` also evaluate from the perspective of the player on the move, the value can be returned directly. \n",
    "Furthermore, the case distinction is completely omitted and only the code for the maximizing player is needed. There the recursive call of the `_value` function changes to `value = -1 * self._value(board, depth - 1, -beta, -alpha)`. The return value, as well as alpha and beta, are negated to be from the player's perspective on the move. Additionally, alpha and beta must be swapped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _value(self, board: chess.Board, depth: int, alpha: int, beta: int) -> int:\n",
    "    if score := self.evaluator.evaluate(board):\n",
    "        return score\n",
    "    if depth == 0:\n",
    "        return self.evaluator.heuristic(board)\n",
    "\n",
    "    for move in board.legal_moves:\n",
    "        board.push(move)\n",
    "        value = -1 * self._value(board, depth - 1, -beta, -alpha)\n",
    "        board.pop()\n",
    "        if value >= beta:\n",
    "            return value\n",
    "        alpha = max(alpha, value)\n",
    "\n",
    "    return alpha\n",
    "\n",
    "\n",
    "AlphaBetaEngine._value = _value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "The `_evaluate_move` needs to be adjusted so that its returned result is again from the perspective of white as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_move(self, board: chess.Board, move: chess.Move):\n",
    "    board.push(move)\n",
    "    score = self._value(\n",
    "        board,\n",
    "        self.look_ahead_depth,\n",
    "        -self.evaluator.value_checkmate,\n",
    "        self.evaluator.value_checkmate\n",
    "    )\n",
    "    score *= self.PLAYER_MULTIPLIER[board.turn]\n",
    "    board.pop()\n",
    "    return ScoredMove(score=score, move=move)\n",
    "\n",
    "\n",
    "AlphaBetaEngine._evaluate_move = _evaluate_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "Now the `middlegame_board` position can also be analyzed by the `NegaMax` variant and afterwards it can be verified that all three implementations actually evaluate the position in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "engine = AlphaBetaEngine(evaluator=standard_evaluator, look_ahead_depth=2)\n",
    "# engine = AlphaBetaEngine(evaluator=standard_evaluator, look_ahead_depth=3)\n",
    "tree = utils.min_max_tree.add_tree_to_engine(engine)\n",
    "result_negamax = engine.analyse(middlegame_board)\n",
    "tree.count()\n",
    "\n",
    "assert result_alphabeta == result_negamax"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b42f3920614829e661a3e80085f50421aa71f403bff6adf1f40efa6d26183877"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
