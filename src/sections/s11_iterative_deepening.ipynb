{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no-python-export",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open('style.css') as file:\n",
    "    css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no-python-export",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Autload python modules by default\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Convert notebooks to python, so they can be loaded effiently\n",
    "from utils.jupyter_loader import JupyterLoader\n",
    "\n",
    "loader = JupyterLoader()\n",
    "loader.load_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "# Iterative Deepening\n",
    "\n",
    "The algorithms shown so far have the advantage of a low memory consumption, as usual in a depth-first searches. Thus, at most the current path must always be kept in memory. A disadvantage is, however, that it is difficult to build in a time break. If the search is simply aborted after a certain time, some paths have been evaluated completely, while other paths have not been considered at all. Another problem currently with the `AlphaBeta Pruning Algorithm` is that in the optimal case, good moves should be considered first, in order to be able to prune as many paths as possible. So far, however, there is no heuristic to perform this sorting of the moves.\n",
    "\n",
    "The idea of iterative depth-first search provides a possible solution to both problems. In contrast to the normal depth-first search, the depth is iteratively increased until the maximum depth is reached. The obvious disadvantage of this is more overhead, since nodes that have already been analyzed are looked at again in the next iterative pass. However, as seen in previous examples, the number of new nodes increases so dramatically for each increase in search depth that re-analyzing previous nodes is negligible.\n",
    "\n",
    "The advantage of iterative depth-first search, however, is that the results obtained from previous runs with lower search depths can be used. On the one hand, these results can be returned if the time limit expires in the next run. On the other hand, based on the previous run, the sorting of moves for the next one can be done. \n",
    "\n",
    "At first only the iterative deepening algorithmn itself shall be implemented in a new class `IterativeAlphaBeta`, which inherits from `AlphaBetaEngine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converted_notebooks.s10_alpha_beta_engine import AlphaBetaEngine\n",
    "from converted_notebooks.s08_evaluation import Evaluator\n",
    "\n",
    "\n",
    "class IterativeAlphaBeta(AlphaBetaEngine):\n",
    "\n",
    "    def __init__(self, evaluator: Evaluator, max_look_ahead_depth: int):\n",
    "        self.evaluator = evaluator\n",
    "        self.max_look_ahead_depth = max_look_ahead_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "The `_evaluate_move` method must be adapted so that the depth is now a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "from converted_notebooks.s04_engine_interface import ScoredMove, LowestScore, HighestScore\n",
    "\n",
    "\n",
    "def _evaluate_move(self, board: chess.Board, move: chess.Move, depth: int):\n",
    "    board.push(move)\n",
    "    score = self._value(board, depth - 1, LowestScore, HighestScore)\n",
    "    board.pop()\n",
    "    return ScoredMove(score=score.white(), move=move)\n",
    "\n",
    "\n",
    "IterativeAlphaBeta._evaluate_move = _evaluate_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "In the `_evaluate_moves` method, a simple loop can now be built in, which increases the depth step by step until the desired maximum depth is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "def _evaluate_moves(self, board: chess.Board):\n",
    "    logging.info(f\"Max depth: {self.max_look_ahead_depth}\")\n",
    "\n",
    "    for depth in range(1, self.max_look_ahead_depth + 1):\n",
    "        scoredMoves = [\n",
    "            self._evaluate_move(board, move, depth)\n",
    "            for move in board.legal_moves\n",
    "        ]\n",
    "\n",
    "        logging.info(f\"Depth {depth}\")\n",
    "        logging.debug(f\"result: {scoredMoves}\\n\")\n",
    "\n",
    "    return scoredMoves\n",
    "\n",
    "\n",
    "IterativeAlphaBeta._evaluate_moves = _evaluate_moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "Again, it can be verified that the new implementation still evaluates the already known position in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from converted_notebooks.s09_minimax_engine import middlegame_board, result_minimax\n",
    "from converted_notebooks.s08_evaluation import standard_evaluator\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "engine = IterativeAlphaBeta(\n",
    "    evaluator=standard_evaluator, max_look_ahead_depth=3\n",
    ")\n",
    "result_iterativeAlphaBeta = engine.analyse(middlegame_board)\n",
    "\n",
    "assert result_iterativeAlphaBeta == result_minimax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "# Transposition tables\n",
    "\n",
    "In the last section of this chapter we will look at transposition tables. Essentially, they are a cache for the search tree that serves several purposes. The first use case and eponym are transpositions. In chess one speaks of a transposition, if the same position is obtained by different move sequences. In this case, with the help of a cache, the position has to be evaluated only once. In some algorithms, such as the ['MTD(f) algorithm'](https://www.chessprogramming.org/MTD(f)), a node of the search tree is also evaluated several times in succession. In this case it is therefore possible to fall back on the already calculated results in the cache. Finally, it is also possible, e.g. in an iterative deepening framework, to perform move ordering after a search pass through the cache. A possible implementation of the [`principal variation search`](https://www.chessprogramming.org/Principal_Variation_Search), for example, uses the cache to determine the principal variation of the previous search pass.\n",
    "\n",
    "First, we have to consider how an entry in the cache is structured. Besides the value of a node, the depth for which this value is valid is of course important. Furthermore, it could be seen with the `AlphaBeta algorithm` that it performs optimizations based on the `alpha` and `beta` value and thus on previously considered other paths in the tree. Thus, the value is not necessarily valid in a transposition that was reached by other means. One possibility would therefore be to store `alpha` and `beta` as well. \n",
    "\n",
    "A more meaningful way, however, is to classify the different nodes within a search tree:\n",
    "\n",
    "1. `alpha < score < beta`: All child nodes have been examined and the value is always exact, even for transpositions. This is often referred to as `PV-Node`.\n",
    "1. `alpha < beta <= score`: The search was aborted by a beta cut, therefore it is also called a `Cut-Node`. The score here is a lower limit, the actual value could be larger. \n",
    "1. `score <= alpha < beta`: Here all child nodes were examined too, however beta cutoffs occured. These nodes are also referred to as `All-Node`. Here the value acts as an upper bound, the actual value could be lower. \n",
    "\n",
    "In general it can be said that at least the root node and the leftmost node must be `PV-Nodes`, because `alpha` and `beta` cannot cause cuttofs there yet. The children of `PV-Nodes` can in turn also be `PV-Nodes` or `Cut-Nodes` if a beta cuttoff has occurred. After `Cut-Nodes` follow in each case alternating `All Nodes` and again `Cut-Nodes`. cite:[Node_Types].\n",
    "\n",
    "The node type is stored in an enum. As designation the effect of the value was chosen, therefore, whether this is exact, a lower limit or an upper limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from functools import total_ordering\n",
    "\n",
    "# TODO: Explain Ordering\n",
    "\n",
    "\n",
    "@total_ordering\n",
    "class NodeType(Enum):\n",
    "    EXACT = 0  # PV Node\n",
    "    UPPER_BOUND = 1  # All Node\n",
    "    LOWER_BOUND = 2  # Cut Node\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        if self.__class__ is other.__class__:\n",
    "            return self.value < other.value\n",
    "        return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "Based on this a dedicated data class is created\n",
    "to store the node type, value and depth of a position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from chess.engine import PovScore\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CachedPositionEntry:\n",
    "    type: NodeType\n",
    "    value: PovScore\n",
    "    depth: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "A dedicated class `AlphaBetaCache` is created\n",
    "to provide an abstraction for storing and loading entries.\n",
    "The entries are interally stored in a `dict` \n",
    "and wrapped methods are provided to reset the cache\n",
    "or get its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaBetaCache:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cache = dict()\n",
    "\n",
    "    def clear(self):\n",
    "        self.cache.clear()\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "For a cache entry their needs to be a key to identify the position.\n",
    "This key is calculated using the method `get_key`,\n",
    "which takes a board as input and returns a key representing the position in a unique way.\n",
    "As this function is called wether there is a matching cached entry or not\n",
    "it needs to be fast.\n",
    "A popular way of identifying positions in chess engines is the usage of [Zobrist Hashes](https://www.chessprogramming.org/Zobrist_Hashing),\n",
    "as they can be determined incrementally cite:[Zobrist_Hashing].\n",
    "As the `python-chess` library already has an internal method `_transposition_key`\n",
    "this is used.\n",
    "It is rather quick\n",
    "as only internal representations of the position are used to calculate it\n",
    "and the calculation is already done on every `push` and `pop`.\n",
    "To use Zobrist Hashes in a useful way\n",
    "the `python-chess` library would need to be patched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(self, board: chess.Board):\n",
    "    return board._transposition_key()\n",
    "\n",
    "\n",
    "AlphaBetaCache.get_key = get_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "To save an entry to the cache its node type needs to be calculated.\n",
    "This is done by the auxilary function `_get_node_type`\n",
    "which takes a value, the depth, alpha and beta as parameters and returns the node type.\n",
    "It implements the typing as described above \n",
    "and additionally recognizes the leaf nodes as PV Nodes by their depth of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess.engine import Score\n",
    "\n",
    "\n",
    "def _get_node_type(\n",
    "    self, value: Score, depth: int, alpha: Score, beta: Score\n",
    ") -> NodeType:\n",
    "    if value <= alpha:\n",
    "        return NodeType.UPPER_BOUND\n",
    "    if value >= beta:\n",
    "        return NodeType.LOWER_BOUND\n",
    "    return NodeType.EXACT\n",
    "\n",
    "\n",
    "AlphaBetaCache._get_node_type = _get_node_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "The `store_cache` method\n",
    "adds an entry \n",
    "defined by the key returned by the `get_key` method\n",
    "to the cache.\n",
    "The entry consists of the node type as returned by the `_get_node_type` method,\n",
    "the value and the current depth.\n",
    "The parameters are therefore the parameters of `_get_node_type` (value, alpha, beta) and the key.\n",
    "\n",
    "Initially the cache is checked for an already existing entry.\n",
    "If there is a matching entry and its depth is deeper than the current depth, \n",
    "the current value is not stored in the cache \n",
    "as the other value has been calculated using more ressources already.\n",
    "This is called depth first replacement\n",
    "and is a popular way to handle replacing cache values,\n",
    "but it is not the only way to do so. \n",
    "If there is no such entry,\n",
    "the node type is evaluated and the tuple as described above is added to the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_cache(\n",
    "    self, key: int, value: PovScore, depth: int, alpha: Score, beta: Score\n",
    "):\n",
    "    # depth first replacement\n",
    "    entry = self.cache.get(key)\n",
    "    if entry and entry.depth >= depth:\n",
    "        return\n",
    "\n",
    "    node_type = self._get_node_type(value.relative, depth, alpha, beta)\n",
    "    self.cache[key] = CachedPositionEntry(node_type, value, depth)\n",
    "\n",
    "\n",
    "AlphaBetaCache.store_cache = store_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "The `load_cache` method returns an entry and it's type from the cache given a key.\n",
    "Additionaly the depth is supplied as a parameter\n",
    "as the cache entry is only relevant \n",
    "if it has the same or a greater depth.\n",
    "If there is no matching entry\n",
    "or the depth of the cached value is too shallow\n",
    "a `KeyError` exception is thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def load_cache(self, key: int, depth: int) -> Tuple[NodeType, PovScore]:\n",
    "    entry = self.cache[key]\n",
    "    if entry.depth < depth:\n",
    "        raise KeyError\n",
    "\n",
    "    return (entry.type, entry.value)\n",
    "\n",
    "\n",
    "AlphaBetaCache.load_cache = load_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "The class `AlphaBetaCache` is fully implemented,\n",
    "but to use it the `_value` needs to be aware of it.\n",
    "Therefore a decorator `cache_alpha_beta` is created\n",
    "to check the cache for a matching entry\n",
    "and to store the new result\n",
    "if there was no matching entry yet.\n",
    "\n",
    "The decorator calculates the key for the current position \n",
    "and tries to get a matching entry from the cache \n",
    "via `load_cache`.\n",
    "If there is such an entry a differentiation needs to be made;\n",
    "an exact value can be returned immediately\n",
    "while a lower bound may increase `alpha`\n",
    "and an upper bound may decrease `beta`.\n",
    "This might lead to a cutoff\n",
    "in case the new `alpha` is at least `beta`\n",
    "and the cached value being returned immediately.\n",
    "\n",
    "If the value is not returned immediately\n",
    "or there was no value in the cache at all\n",
    "the `value_function` is called\n",
    "and the returned value is stored in the cache via `store_cache`\n",
    "before returning the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess.engine import Score, PovScore\n",
    "from functools import wraps\n",
    "\n",
    "\n",
    "def cache_alpha_beta(value_function):\n",
    "\n",
    "    @wraps(value_function)\n",
    "    def cached_value(\n",
    "        self, board: chess.Board, depth: int, alpha: Score, beta: Score\n",
    "    ) -> PovScore:\n",
    "        cacheKey = self.cache.get_key(board)\n",
    "        try:\n",
    "            type, value = self.cache.load_cache(cacheKey, depth)\n",
    "\n",
    "            if type == NodeType.EXACT:\n",
    "                return value\n",
    "            elif type == NodeType.LOWER_BOUND:\n",
    "                alpha = max(value.relative, alpha)\n",
    "            else:  # type == NodeType.UPPER_BOUND\n",
    "                beta = min(value.relative, beta)\n",
    "\n",
    "            if alpha >= beta:\n",
    "                return value\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        value = value_function(self, board, depth, alpha, beta)\n",
    "        self.cache.store_cache(cacheKey, value, depth, alpha, beta)\n",
    "        return value\n",
    "\n",
    "    return cached_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "To use the cache a dedicated class `IterativeAlphaBetaCached` is created inheriting from `IterativeAlphaBeta`.\n",
    "On construction of an object of the `IterativeAlphaBetaCached` class\n",
    "the cache is created\n",
    "and each call of `_evaluate_moves` empties the cache\n",
    "to prevent stale data influencing the analysis.\n",
    "To really use the cache\n",
    "the `_value` function gets the newly created `cache_alpha_beta` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess.engine import Score, PovScore\n",
    "\n",
    "\n",
    "class IterativeAlphaBetaCached(IterativeAlphaBeta):\n",
    "\n",
    "    def __init__(self, evaluator: Evaluator, max_look_ahead_depth: int):\n",
    "        super().__init__(evaluator, max_look_ahead_depth)\n",
    "        self.cache = AlphaBetaCache()\n",
    "\n",
    "    def _evaluate_moves(self, board: chess.Board):\n",
    "        self.cache.clear()\n",
    "        return super()._evaluate_moves(board)\n",
    "\n",
    "    @cache_alpha_beta\n",
    "    def _value(\n",
    "        self, board: chess.Board, depth: int, alpha: Score, beta: Score\n",
    "    ) -> PovScore:\n",
    "        return super()._value(board, depth, alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "source": [
    "As the cache usage should only influence the performance\n",
    "the result of the caching engine should match that of the non-caching engine.\n",
    "This is checked here as seen in previous examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no-python-export"
    ]
   },
   "outputs": [],
   "source": [
    "import utils.min_max_tree\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "engine = IterativeAlphaBetaCached(\n",
    "    evaluator=standard_evaluator, max_look_ahead_depth=3\n",
    ")\n",
    "tree = utils.min_max_tree.add_tree_to_engine(engine)\n",
    "result_iterativeAlphaBetaCached = engine.analyse(middlegame_board)\n",
    "\n",
    "assert result_iterativeAlphaBetaCached == result_iterativeAlphaBeta"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  },
  "vscode": {
   "interpreter": {
    "hash": "c356581f63fdb862d21b8530e2fecebf3d406a06e3d3208273931edc8a0b30c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
