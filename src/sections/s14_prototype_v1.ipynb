{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open('style.css') as file:\n",
    "    css = file.read()\n",
    "HTML(css)\n",
    "\n",
    "# Autload python modules by default\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Convert notebooks to python, so they can be loaded effiently\n",
    "from utils.jupyer_loader import JupyerLoader\n",
    "\n",
    "loader = JupyerLoader()\n",
    "loader.load_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype 1 \n",
    "\n",
    "In the last chapters many ideas have been introduced and the engine was successively improved. One concesequence though is that the necessary code is split across multiple files. The goal of this chapter is to show one complete implementation of the current engine. Additionally some last improvement is done to the `play` function. Up to now it was just using `analyse` internally and would calculate an exact score for every possible move. But as we are only interested in the best move, there is some room for improvement here.\n",
    "\n",
    "We define a new engine `PrototypeV1Engine` that inherits the base interface `Engine`. It will contain the complete implementation of the algorithms introduced in the previous chapters, which will not be explained again here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converted_notebooks.s04_engine_interface import Engine, ScoredMove\n",
    "from converted_notebooks.s12_simplified_evaluation import DetailedMove, IncrementalEvaluator\n",
    "from converted_notebooks.s11_iterative_deepening import AlphaBetaCache, NodeType, cache_alpha_beta\n",
    "\n",
    "import chess\n",
    "import random\n",
    "\n",
    "\n",
    "class PrototypeV1Engine(Engine):\n",
    "    PLAYER_MULTIPLIER = {\n",
    "        chess.WHITE: 1, chess.BLACK: -1\n",
    "    }\n",
    "\n",
    "    def __init__(self, evaluator: IncrementalEvaluator, max_look_ahead_depth):\n",
    "        self.evaluator = evaluator\n",
    "        self.max_look_ahead_depth = max_look_ahead_depth\n",
    "        self.cache = AlphaBetaCache()\n",
    "\n",
    "    @cache_alpha_beta\n",
    "    def _value(\n",
    "        self, board: chess.Board, depth: int, alpha: int, beta: int\n",
    "    ) -> int:\n",
    "        if (score := self.evaluator.evaluate(board)) is not None:\n",
    "            return score\n",
    "        if depth == 0:\n",
    "            return self._quiescence(board, alpha, beta)\n",
    "\n",
    "        for move in board.legal_moves:\n",
    "            detailedMove = DetailedMove(board, move)\n",
    "\n",
    "            self.evaluator.push(detailedMove)\n",
    "            board.push(move)\n",
    "            value = -1 * self._value(board, depth - 1, -beta, -alpha)\n",
    "            board.pop()\n",
    "            self.evaluator.pop()\n",
    "\n",
    "            if value >= beta:\n",
    "                return value\n",
    "            alpha = max(alpha, value)\n",
    "\n",
    "        return alpha\n",
    "\n",
    "    def _quiescence(self, board: chess.Board, alpha: int, beta: int) -> int:\n",
    "        stand_pat = self.evaluator.get_score()\n",
    "\n",
    "        if stand_pat >= beta:\n",
    "            return beta\n",
    "        alpha = max(alpha, stand_pat)\n",
    "\n",
    "        for move in board.generate_legal_captures():\n",
    "            detailedMove = DetailedMove(board, move)\n",
    "\n",
    "            if move.promotion is None:\n",
    "                if self._canDeltaPrune(stand_pat, alpha, detailedMove):\n",
    "                    continue\n",
    "                if self._seeCapture(board, detailedMove) < 0:\n",
    "                    continue\n",
    "\n",
    "            self.evaluator.push(detailedMove)\n",
    "            board.push(move)\n",
    "            value = -1 * self._quiescence(board, -beta, -alpha)\n",
    "            board.pop()\n",
    "            self.evaluator.pop()\n",
    "\n",
    "            if value >= beta:\n",
    "                return value\n",
    "            alpha = max(alpha, value)\n",
    "        return alpha\n",
    "\n",
    "    def _canDeltaPrune(\n",
    "        self, stand_pat: int, alpha: int, detailedMove: DetailedMove\n",
    "    ):\n",
    "        pieceValue = self.evaluator.piece_values[\n",
    "            detailedMove.capturedPiece.piece.piece_type]\n",
    "        bestAlpha = stand_pat + pieceValue + 200\n",
    "        return bestAlpha < alpha\n",
    "\n",
    "    def _seeCapture(self, board: chess.Board, detailedMove: DetailedMove):\n",
    "        board.push(detailedMove.move)\n",
    "        capturedPiece = detailedMove.capturedPiece\n",
    "        value = self.evaluator.piece_values[\n",
    "            capturedPiece.piece.piece_type\n",
    "        ] - self._see(board, detailedMove.placedPiece.square)\n",
    "        board.pop()\n",
    "        return value\n",
    "\n",
    "    def _see(self, board: chess.Board, square: chess.Square):\n",
    "        attackers_squares = [\n",
    "            square for square in board.attackers(board.turn, square)\n",
    "            if not board.is_pinned(board.turn, square)\n",
    "        ]\n",
    "        if not attackers_squares:\n",
    "            return 0\n",
    "\n",
    "        attacker_square = min(\n",
    "            attackers_squares,\n",
    "            key=lambda attackers_square: board.piece_type_at(attackers_square)\n",
    "        )\n",
    "        capturedPiece = board.piece_type_at(square)\n",
    "\n",
    "        detailedMove = DetailedMove(\n",
    "            board, chess.Move(from_square=attacker_square, to_square=square)\n",
    "        )\n",
    "        board.push(detailedMove.move)\n",
    "        value = max(\n",
    "            0,\n",
    "            self.evaluator.piece_values[capturedPiece] -\n",
    "            self._see(board, detailedMove.placedPiece.square)\n",
    "        )\n",
    "\n",
    "        board.pop()\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the `analyse` methhod is implemented. The goal of this method is to evaluate all next moves and return them as a sorted list. To implement this two function `_evaluate_nove` and `_evaluate_moves` are needed. All of these have been shown already in previous chapters, so there will be just short descriptions for a reminder.\n",
    "\n",
    "The `_evaluate_move` function will score the given move by using the `_value` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_move(\n",
    "    self, board: chess.Board, move: chess.Move, depth: int\n",
    ") -> ScoredMove:\n",
    "    self.evaluator.push(DetailedMove(board, move))\n",
    "    board.push(move)\n",
    "\n",
    "    score = self._value(\n",
    "        board,\n",
    "        depth,\n",
    "        -self.evaluator.value_checkmate - 1,\n",
    "        self.evaluator.value_checkmate + 1\n",
    "    )\n",
    "    score *= self.PLAYER_MULTIPLIER[board.turn]\n",
    "\n",
    "    board.pop()\n",
    "    self.evaluator.pop()\n",
    "\n",
    "    return ScoredMove(score=score, move=move)\n",
    "\n",
    "\n",
    "PrototypeV1Engine._evaluate_move = _evaluate_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_evaluate_moves` implement the iterative deepening algorithm and thus will score all moves with the `_evaluate_move` method starting at a depth of 0. It will then successively increase the depth until the max look ahead depth is reached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_moves(self, board: chess.Board) -> list[ScoredMove]:\n",
    "    print(f\"Max depth: {self.max_look_ahead_depth}\")\n",
    "    self.cache.clear()\n",
    "    self.evaluator.init(board)\n",
    "\n",
    "    for depth in range(self.max_look_ahead_depth + 1):\n",
    "        scoredMoves = [\n",
    "            self._evaluate_move(board, move, depth)\n",
    "            for move in board.legal_moves\n",
    "        ]\n",
    "\n",
    "        print(f\"Depth {depth}\")\n",
    "\n",
    "    return scoredMoves\n",
    "\n",
    "\n",
    "PrototypeV1Engine._evaluate_moves = _evaluate_moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then `analyse` uses this method to get a list of scored moves and will return this sorted to the caller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse(self, board: chess.Board) -> list[ScoredMove]:\n",
    "    nextMoves = self._evaluate_moves(board.copy(stack=False))\n",
    "\n",
    "    whitesTurn = board.turn is chess.WHITE\n",
    "    nextMoves.sort(reverse=whitesTurn)\n",
    "\n",
    "    return nextMoves\n",
    "\n",
    "\n",
    "PrototypeV1Engine.analyse = analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides `analyse` the interface also requires us to implement the `play` function. In contrast to `analyse`, `play` should only return the best move. Therefore the iterative deepening algorithm could call directly the `_value` function. The problem though is that `_value` gives us only the best score, but not the corresponding move. There are many possible solutions to this problem. One of them is to rewrite `_value` so it actually returns the move. This implemention instead makes use of the cache to find the best move afterwards. \n",
    "\n",
    "The `_find_move` method takes a chess board `board` and the score `score` of the best move as parameters. Its goal is to find a corresponding move by querying the cache and return it. It will therefore iterate over all moves and get the cache entries for these if existent. To be the best move the cache entry type needs to be exact and the stored value must be the same as score negated. The negation is needed because the cache entry is for a position one move further than the passed board and therefore the perspective changed. There can be multiple best moves, therefore they are saved in a list and a random element is returned from it in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_move(self, board: chess.Board, score: int) -> chess.Move:\n",
    "    best_moves = []\n",
    "    for move in board.legal_moves:\n",
    "        board.push(move)\n",
    "        cacheKey = self.cache.get_key(board)\n",
    "        board.pop()\n",
    "\n",
    "        try:\n",
    "            type, value = self.cache.load_cache(cacheKey, self.max_look_ahead_depth - 1)\n",
    "\n",
    "            if type == NodeType.EXACT and value == -score:\n",
    "                best_moves.append(move)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    assert best_moves, \"No best move found with the given score\"\n",
    "    return random.choice(best_moves)\n",
    "\n",
    "\n",
    "PrototypeV1Engine._find_move = _find_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we can implement the iterative deepening algorithm for `play`. The method `_find_best_move` works similary to `_evaluate_moves`. It will also take the chess board `board` as a parameter. But instead of returning a list of all scored moves, it will just return the best move. To do this it calls directly `_value` in its loop. At the end it uses the previously defined `_find_move` method to get the best move from the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_best_move(self, board: chess.Board) -> chess.Move:\n",
    "    print(f\"Max depth: {self.max_look_ahead_depth}\")\n",
    "    self.cache.clear()\n",
    "    self.evaluator.init(board)\n",
    "\n",
    "    for depth in range(self.max_look_ahead_depth + 1):\n",
    "        score = self._value(\n",
    "            board,\n",
    "            depth,\n",
    "            -self.evaluator.value_checkmate - 1,\n",
    "            self.evaluator.value_checkmate + 1\n",
    "        )\n",
    "        print(f\"Depth {depth}\")\n",
    "\n",
    "    return self._find_move(board, score)\n",
    "\n",
    "\n",
    "PrototypeV1Engine._find_best_move = _find_best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the `play` method needs to be implemented. It will simply return a `chess.engine.PlayResult` with the best move found by the `_find_best_move` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(self, board: chess.Board) -> chess.engine.PlayResult:\n",
    "    return chess.engine.PlayResult(\n",
    "        move=self._find_best_move(board), ponder=None\n",
    "    )\n",
    "\n",
    "\n",
    "PrototypeV1Engine.play = play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is then possible to play against the prototype engine with the human engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# from converted_notebooks.s06_play import play_game\n",
    "# from converted_notebooks.s07_human_engine import HumanEngine\n",
    "# from converted_notebooks.s12_simplified_evaluation import incremental_simplified_evaluator\n",
    "\n",
    "# random.seed(42)\n",
    "\n",
    "# board = chess.Board()\n",
    "# play_game(\n",
    "#     board,\n",
    "#     HumanEngine(),\n",
    "#     PrototypeV1Engine(evaluator=incremental_simplified_evaluator, max_look_ahead_depth=3),\n",
    "#     display_board=True,\n",
    "#     log_moves=True\n",
    "# )\n",
    "# print(board.outcome())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b42f3920614829e661a3e80085f50421aa71f403bff6adf1f40efa6d26183877"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
