{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell",
     "no-python-export"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open('style.css') as file:\n",
    "    css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell",
     "no-python-export"
    ]
   },
   "outputs": [],
   "source": [
    "# Autload python modules by default\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Convert notebooks to python, so they can be loaded effiently\n",
    "from utils.jupyter_loader import JupyterLoader\n",
    "\n",
    "loader = JupyterLoader()\n",
    "loader.load_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move Ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing any further optimization, let's first check the current performance of the latest engine. For the middlegame position the `PrototypeV1Engine` engine visits `25139` nodes and needs approximatly 5 seconds on our machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import utils.min_max_tree\n",
    "import IPython.display\n",
    "from converted_notebooks.s09_minimax_engine import middlegame_board\n",
    "from converted_notebooks.s12_simplified_evaluation import incremental_simplified_evaluator\n",
    "from converted_notebooks.s14_prototype_v1 import PrototypeV1Engine\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "prototype_v1_engine = PrototypeV1Engine(\n",
    "    evaluator=incremental_simplified_evaluator, max_look_ahead_depth=4\n",
    ")\n",
    "\n",
    "tree = utils.min_max_tree.add_tree_to_engine(prototype_v1_engine)\n",
    "prototype_v1_engine.play(middlegame_board)\n",
    "print(tree.count())\n",
    "\n",
    "# %timeit prototype_v1_engine.play(middlegame_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key reasons to do iterative deepening in the first place, is to make use of the results from previous iterations. Provided a good evaluation function is used, a reasonable assumption is that the evaluation of each move won't change much if it's analysed one depth further. This information can be used to sort moves in the next iteration. Alpha Beta prunning leads to the best results if the best move is searched for, therefore we sort the moves according to their score. \n",
    "\n",
    "The `_value` method will use a helper function `_get_moves` to get a sorted list of moves rather than `board.legal_moves`. The helper method takes the current board `board` and the depth `depth` as parameter and returns the list of all possible next moves, which are sorted by their value in the previous iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converted_notebooks.s11_iterative_deepening import cache_alpha_beta\n",
    "from converted_notebooks.s12_simplified_evaluation import DetailedMove\n",
    "from converted_notebooks.s14_prototype_v1 import PrototypeV1Engine\n",
    "import chess\n",
    "from chess.engine import PovScore\n",
    "\n",
    "\n",
    "class MoveOrderingEngine(PrototypeV1Engine):\n",
    "\n",
    "    @cache_alpha_beta\n",
    "    def _value(\n",
    "        self, board: chess.Board, depth: int, alpha: int, beta: int\n",
    "    ) -> PovScore:\n",
    "        if (score := self.evaluator.evaluate(board)) is not None:\n",
    "            return score\n",
    "        if depth == 0:\n",
    "            return self._quiescence(board, alpha, beta)\n",
    "\n",
    "        for move in self._get_moves(board, depth):\n",
    "            detailedMove = DetailedMove(board, move)\n",
    "\n",
    "            self.evaluator.push(detailedMove)\n",
    "            board.push(move)\n",
    "            value = self._value(board, depth - 1, -beta,\n",
    "                                -alpha).pov(not board.turn)\n",
    "            board.pop()\n",
    "            self.evaluator.pop()\n",
    "\n",
    "            if value >= beta:\n",
    "                return PovScore(value, board.turn)\n",
    "            alpha = max(alpha, value)\n",
    "\n",
    "        return PovScore(alpha, board.turn)\n",
    "\n",
    "    def _get_moves(self, board: chess.Board, depth: int):\n",
    "        cached_moves = []\n",
    "        uncached_moves = []\n",
    "        for move in board.legal_moves:\n",
    "            board.push(move)\n",
    "            cache_key = self.cache.get_key(board)\n",
    "            board.pop()\n",
    "\n",
    "            try:\n",
    "                # depth - 2 as we are looking at one move further and at the previous iteration with depth - 1\n",
    "                _, value = self.cache.load_cache(cache_key, depth - 2)\n",
    "                cached_moves.append((value.relative, move))\n",
    "            except KeyError:\n",
    "                uncached_moves.append(move)\n",
    "\n",
    "        cached_moves.sort(reverse=False, key=lambda x: x[0])\n",
    "        return [cached_move[1] for cached_move in cached_moves] + uncached_moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we ran the same analyse as before with the new defined engine, then the number of nodes drasticall decreases from `25139` to `12911`. Unfortunatly, due to the overhead of the added code, the time decreased only by approximatly one second from `5` seconds to `4` seconds on our machine. Nevertheless, this is still a huge improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import utils.min_max_tree\n",
    "import IPython.display\n",
    "from converted_notebooks.s09_minimax_engine import middlegame_board\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# IPython.display.display(middlegame_board)\n",
    "\n",
    "move_ordering_engine = MoveOrderingEngine(\n",
    "    evaluator=incremental_simplified_evaluator, max_look_ahead_depth=4\n",
    ")\n",
    "\n",
    "# tree = utils.min_max_tree.add_tree_to_engine(move_ordering_engine)\n",
    "# move_ordering_engine.play(middlegame_board)\n",
    "# print(tree.count())\n",
    "\n",
    "%timeit move_ordering_engine.play(middlegame_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting every move according to their score implies that the principal variation, therefore best line in the previous iteration, is searched first. Furthermore, at Cut Nodes the move that lead to the cut in the previous iteration, also called refutation move, is searched first as well. These are the two most important move criteria according to [the chessprogramming wiki](https://www.chessprogramming.org/Move_Ordering#Typical_move_ordering). The only downside of the current approach is that the best move or refutation move is not already stored in the transposition table. Changing this wouldn't improve the number of visited nodes, but the time needed to visit one node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, another look should be taken on the `quiescence search`. We can calculate how many nodes are visited in the quiescence search. With `513446` the number of nodes spent in the quiescence search is by factor 50 higher than in the normal alpha beta search. This doesn't mean though that it is not worth it to optimize the `_value` function, quite the opposite is true. Every node visited less in the `_value` function will lead to a huge decrease of nodes in the `quiescence` search. Nonetheless, it might be still useful to try to optimize `_quiescence` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import utils.min_max_tree\n",
    "import IPython.display\n",
    "from converted_notebooks.s09_minimax_engine import middlegame_board\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "move_ordering_engine = MoveOrderingEngine(\n",
    "    evaluator=incremental_simplified_evaluator, max_look_ahead_depth=5\n",
    ")\n",
    "\n",
    "tree = utils.min_max_tree.add_tree_to_engine(move_ordering_engine)\n",
    "move_ordering_engine.play(middlegame_board)\n",
    "print(tree.count(quiesce=True))\n",
    "\n",
    "# %timeit move_ordering_engine.play(middlegame_board)\n",
    "\n",
    "# 3.91 s ± 67.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "# 12911 nodes visited\n",
    "# 151349 paths pruned\n",
    "# 513446 quiesce nodes visited\n",
    "# 333054 quiesce paths pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a new class `QuiescenceMoveOrderingEngine` which inherits from `MoveOrderingEngine`. The `_quiescence` uses a helper method `_get_quiescence_detailed_moves` to get all moves that should be checked in sorted order. The optimization like delta pruning or static exchange evaluation are moved into that function as well. The new `_get_quiescence_detailed_moves` method takes the board `board`, the standing pat `stand_path` and the alpha and beta value `alpha` and `beta` as parameter and returns a sorted list of next moves. As before, only captures are considered and some of these are pruned by delta pruning or static exchange evaluation. The moves are sorted by MVV-LVA, which stands fore most valuable victim - least valuable attacker. Therefore the moves are first sorted by the most valuable captured piece and in case of an qual captured then sorted by the least valuable attacker. As the value of the captured piece and moved piece have to be calculated anyway, the two methods `_seeCapture` and `_canDeltaPrune` have been rewritten to use this information for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converted_notebooks.s12_simplified_evaluation import IncrementalEvaluator\n",
    "from chess.engine import Score, Cp, Mate, PovScore\n",
    "\n",
    "\n",
    "class QuiescenceMoveOrderingEngine(MoveOrderingEngine):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        evaluator: IncrementalEvaluator,\n",
    "        max_look_ahead_depth,\n",
    "        use_static_exchange_evaluation=False\n",
    "    ):\n",
    "        super().__init__(evaluator, max_look_ahead_depth)\n",
    "        self.use_static_exchange_evaluation = use_static_exchange_evaluation\n",
    "\n",
    "    def _quiescence(self, board: chess.Board, alpha: Score, beta: Score) -> int:\n",
    "        stand_pat = self.evaluator.get_score().relative\n",
    "\n",
    "        if stand_pat >= beta:\n",
    "            return PovScore(beta, board.turn)\n",
    "        alpha = max(alpha, stand_pat)\n",
    "\n",
    "        for detailed_move in self._get_quiescence_detailed_moves(\n",
    "            board, stand_pat, alpha, beta\n",
    "        ):\n",
    "            self.evaluator.push(detailed_move)\n",
    "            board.push(detailed_move.move)\n",
    "            value = self._quiescence(board, -beta, -alpha).pov(not board.turn)\n",
    "            board.pop()\n",
    "            self.evaluator.pop()\n",
    "\n",
    "            if value.is_mate():\n",
    "                value = self._rise_mate(value)\n",
    "\n",
    "            if value >= beta:\n",
    "                return PovScore(value, board.turn)\n",
    "            alpha = max(alpha, value)\n",
    "        return PovScore(alpha, board.turn)\n",
    "\n",
    "    def _get_quiescence_detailed_moves(\n",
    "        self, board: chess.Board, stand_pat: int, alpha: int, beta: int\n",
    "    ):\n",
    "        moves = []\n",
    "        for move in board.generate_legal_captures():\n",
    "            detailedMove = DetailedMove(board, move)\n",
    "\n",
    "            capturedPieceValue = self.evaluator.piece_values[\n",
    "                detailedMove.capturedPiece.piece.piece_type]\n",
    "\n",
    "            movedPieceValue = self.evaluator.piece_values[\n",
    "                detailedMove.movedPiece.piece.piece_type]\n",
    "\n",
    "            if move.promotion is None:\n",
    "                if self._canDeltaPrune(stand_pat, alpha, capturedPieceValue):\n",
    "                    continue\n",
    "\n",
    "                if self._bad_capture(\n",
    "                    board, detailedMove, capturedPieceValue, movedPieceValue\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "            moves.append((capturedPieceValue, movedPieceValue, detailedMove))\n",
    "\n",
    "        # Oder by MVV-LVA (most valuable victim first, least valuable attacker second)\n",
    "        moves.sort(reverse=True, key=lambda x: (x[0], -x[1]))\n",
    "\n",
    "        return [move[2] for move in moves]\n",
    "\n",
    "    def _bad_capture(\n",
    "        self,\n",
    "        board: chess.Board,\n",
    "        detailedMove: DetailedMove,\n",
    "        capturedPieceValue: int,\n",
    "        movedPieceValue: int\n",
    "    ):\n",
    "        value = capturedPieceValue - movedPieceValue\n",
    "        if value >= 0:\n",
    "            return False\n",
    "\n",
    "        if self.use_static_exchange_evaluation:\n",
    "            return self._seeCapture(\n",
    "                board, detailedMove, capturedPieceValue, movedPieceValue\n",
    "            ) < 0\n",
    "        return board.is_attacked_by(\n",
    "            not board.turn, detailedMove.placedPiece.square\n",
    "        )\n",
    "\n",
    "    def _seeCapture(\n",
    "        self,\n",
    "        original_board: chess.Board,\n",
    "        detailedMove: DetailedMove,\n",
    "        capturedPieceValue: int,\n",
    "        movedPieceValue: int\n",
    "    ):\n",
    "        board = original_board.copy()\n",
    "\n",
    "        piece = board.remove_piece_at(detailedMove.movedPiece.square)\n",
    "        value = capturedPieceValue - self._see(\n",
    "            board,\n",
    "            detailedMove.placedPiece.square,\n",
    "            movedPieceValue,\n",
    "            not board.turn\n",
    "        )\n",
    "        board.set_piece_at(detailedMove.movedPiece.square, piece)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def _see(\n",
    "        self,\n",
    "        board: chess.Board,\n",
    "        square: chess.Square,\n",
    "        attacked_piece_value: int,\n",
    "        turn: chess.Color\n",
    "    ):\n",
    "        attackers = [\n",
    "            (square, self.evaluator.piece_values[board.piece_type_at(square)])\n",
    "            for square in board.attackers(turn, square)\n",
    "        ]\n",
    "        if not attackers:\n",
    "            return 0\n",
    "\n",
    "        attacker_square, attacker_piece_value = min(attackers, key=lambda x: x[1])\n",
    "\n",
    "        piece = board.remove_piece_at(attacker_square)\n",
    "        value = max(\n",
    "            0,\n",
    "            attacked_piece_value -\n",
    "            self._see(board, square, attacker_piece_value, not turn)\n",
    "        )\n",
    "        board.set_piece_at(attacker_square, piece)\n",
    "        return value\n",
    "\n",
    "    def _canDeltaPrune(\n",
    "        self, stand_pat: Score, alpha: Score, capturedPieceValue: int\n",
    "    ):\n",
    "        POTENTIAL_POSITION_ADVANTAGE = 200\n",
    "        bestAlpha = Cp(\n",
    "            stand_pat.score() + capturedPieceValue +\n",
    "            POTENTIAL_POSITION_ADVANTAGE\n",
    "        )\n",
    "        return bestAlpha < alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test shows that the number of visited nodes is decreased from `513446` to `467973`, so approximatly 10% of the nodes are saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import utils.min_max_tree\n",
    "import IPython.display\n",
    "from converted_notebooks.s09_minimax_engine import middlegame_board\n",
    "from converted_notebooks.s12_simplified_evaluation import incremental_simplified_evaluator\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "quiescence_move_ordering_engine = QuiescenceMoveOrderingEngine(\n",
    "    evaluator=incremental_simplified_evaluator,\n",
    "    max_look_ahead_depth=4,\n",
    "    use_static_exchange_evaluation=False\n",
    ")\n",
    "\n",
    "# tree = utils.min_max_tree.add_tree_to_engine(quiescence_move_ordering_engine)\n",
    "# quiescence_move_ordering_engine.play(middlegame_board)\n",
    "# print(tree.count(quiesce=True))\n",
    "\n",
    "%timeit quiescence_move_ordering_engine.play(middlegame_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import utils.min_max_tree\n",
    "import IPython.display\n",
    "from converted_notebooks.s09_minimax_engine import middlegame_board\n",
    "from converted_notebooks.s12_simplified_evaluation import incremental_simplified_evaluator\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "quiescence_move_ordering_engine = QuiescenceMoveOrderingEngine(\n",
    "    evaluator=incremental_simplified_evaluator,\n",
    "    max_look_ahead_depth=4,\n",
    "    use_static_exchange_evaluation=True\n",
    ")\n",
    "\n",
    "# tree = utils.min_max_tree.add_tree_to_engine(quiescence_move_ordering_engine)\n",
    "# quiescence_move_ordering_engine.play(middlegame_board)\n",
    "# print(tree.count(quiesce=True))\n",
    "\n",
    "# %timeit quiescence_move_ordering_engine.play(middlegame_board)\n",
    "\n",
    "results = quiescence_move_ordering_engine.analyse(middlegame_board)\n",
    "\n",
    "# Tree Statistics\n",
    "# 12911 nodes visited\n",
    "# 151455 paths pruned\n",
    "# 452292 quiesce nodes visited\n",
    "# 273771 quiesce paths pruned\n",
    "\n",
    "# Tree Statistics\n",
    "# 3427 nodes visited\n",
    "# 87240 paths pruned\n",
    "# 283597 quiesce nodes visited\n",
    "# 173305 quiesce paths pruned\n",
    "\n",
    "# 3.8 s ± 86.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Variation Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converted_notebooks.s11_iterative_deepening import cache_alpha_beta, NodeType\n",
    "from converted_notebooks.s12_simplified_evaluation import DetailedMove\n",
    "from converted_notebooks.s14_prototype_v1 import PrototypeV1Engine\n",
    "import chess\n",
    "\n",
    "\n",
    "class PrincipalVariationSearch(QuiescenceMoveOrderingEngine):\n",
    "\n",
    "    @cache_alpha_beta\n",
    "    def _value(\n",
    "        self, board: chess.Board, depth: int, alpha: Score, beta: Score\n",
    "    ) -> PovScore:\n",
    "        if (score := self.evaluator.evaluate(board)) is not None:\n",
    "            return score\n",
    "        if depth == 0:\n",
    "            return self._quiescence(board, alpha, beta)\n",
    "\n",
    "        search_principal_variation = True\n",
    "        for move in self._get_moves(board, depth):\n",
    "            detailedMove = DetailedMove(board, move)\n",
    "\n",
    "            self.evaluator.push(detailedMove)\n",
    "            board.push(move)\n",
    "\n",
    "            if search_principal_variation:\n",
    "                value = self._value(board, depth - 1, -beta,\n",
    "                                    -alpha).pov(not board.turn)\n",
    "            else:\n",
    "                value = self._zero_width_search(board, depth - 1,\n",
    "                                                -alpha).pov(not board.turn)\n",
    "                if alpha < value < beta:\n",
    "                    value = self._value(board, depth - 1, -beta,\n",
    "                                        -alpha).pov(not board.turn)\n",
    "\n",
    "            board.pop()\n",
    "            self.evaluator.pop()\n",
    "\n",
    "            if value.is_mate():\n",
    "                value = self._rise_mate(value)\n",
    "\n",
    "            if value >= beta:\n",
    "                return PovScore(value, board.turn)\n",
    "\n",
    "            if value > alpha:\n",
    "                alpha = value\n",
    "                search_principal_variation = False\n",
    "\n",
    "        return PovScore(alpha, board.turn)\n",
    "\n",
    "    def _zero_width_search(\n",
    "        self, board: chess.Board, depth: int, beta: Score\n",
    "    ) -> PovScore:\n",
    "        if beta.is_mate():\n",
    "            alpha = Mate(beta.mate() +\n",
    "                         1) if beta > Cp(0) else Mate(beta.mate() - 1)\n",
    "        else:\n",
    "            alpha = Cp(beta.score() - 1)\n",
    "\n",
    "        if (score := self.evaluator.evaluate(board)) is not None:\n",
    "            return score\n",
    "        if depth == 0:\n",
    "            return self._quiescence(board, alpha, beta)\n",
    "\n",
    "        for move in board.generate_legal_moves():\n",
    "            detailedMove = DetailedMove(board, move)\n",
    "\n",
    "            self.evaluator.push(detailedMove)\n",
    "            board.push(move)\n",
    "            value = self._zero_width_search(board, depth - 1,\n",
    "                                            -alpha).pov(not board.turn)\n",
    "            board.pop()\n",
    "            self.evaluator.pop()\n",
    "\n",
    "            if value.is_mate():\n",
    "                value = self._rise_mate(value)\n",
    "\n",
    "            if value >= beta:\n",
    "                return PovScore(value, board.turn)\n",
    "        return PovScore(alpha, board.turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import utils.min_max_tree\n",
    "import IPython.display\n",
    "from converted_notebooks.s09_minimax_engine import middlegame_board\n",
    "from converted_notebooks.s12_simplified_evaluation import incremental_simplified_evaluator\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "principal_variation_search_engine = PrincipalVariationSearch(\n",
    "    evaluator=incremental_simplified_evaluator,\n",
    "    max_look_ahead_depth=4,\n",
    "    use_static_exchange_evaluation=False\n",
    ")\n",
    "\n",
    "# tree = utils.min_max_tree.add_tree_to_engine(principal_variation_search_engine)\n",
    "# principal_variation_search_engine.play(middlegame_board)\n",
    "# print(tree.count(quiesce=True))\n",
    "\n",
    "%timeit principal_variation_search_engine.play(middlegame_board)\n",
    "\n",
    "# Tree Statistics\n",
    "# 3427 nodes visited\n",
    "# 87240 paths pruned\n",
    "# 283597 quiesce nodes visited\n",
    "# 173305 quiesce paths pruned\n",
    "# None\n",
    "\n",
    "# 2.47 s ± 74.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) / SEE\n",
    "# 1.4 s ± 18.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) / without SEE"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  },
  "vscode": {
   "interpreter": {
    "hash": "b42f3920614829e661a3e80085f50421aa71f403bff6adf1f40efa6d26183877"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
