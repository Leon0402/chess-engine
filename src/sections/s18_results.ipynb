{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell",
     "no-python-export"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open('style.css') as file:\n",
    "    css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell",
     "no-python-export"
    ]
   },
   "outputs": [],
   "source": [
    "# Autload python modules by default\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Convert notebooks to python, so they can be loaded effiently\n",
    "from utils.jupyter_loader import JupyterLoader\n",
    "\n",
    "loader = JupyterLoader()\n",
    "loader.load_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Outlook\n",
    "\n",
    "The goal of work was to create an engine that could keep up with good player with an ELO around 1500. Although it is hard to measure exactly the ELO of our engine, the test results have shown that our prototype v2 engine at a depth of 4 is perhaps even slightly stronger than this. Furthermore, it is also able to play quite fast at that level in contrast the prototype v1 engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converted_notebooks.s17_prototype_v2 import s17_PrototypeV2Engine_results, s17_PrototypeV2Engine_see_results, stockfish_results\n",
    "import pandas as pd\n",
    "import IPython.display\n",
    "\n",
    "results = s17_PrototypeV2Engine_results + s17_PrototypeV2Engine_see_results\n",
    "results_frame = pd.DataFrame(results)\n",
    "\n",
    "concatenated_result_frames = pd.concat([\n",
    "    result[1] for result in stockfish_results\n",
    "])\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    IPython.display.display(results_frame.groupby(['engine', 'depth']).sum())\n",
    "    IPython.display.display(concatenated_result_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, there is still a lot of room for improvement. First of all there are various ways how the code itself can be optimized. The most important aspect is perhaps to use a more optimized chess library and perhaps in general another language such as C++. But there have also been some design decision in order to make the code more understandable or be able to introduce new things in a more didactic approach that are not ideal. One of this is the implementation of the cache decorator. Storing values in the cache should rather be done in the `_value` function for multiple reasons. First we can save some code to determine the NodeType, because we can set the node type directly in the `_value` function. By default, it will always be an `ALL` node. If any move is able to increase alpha then we know that we have an `EXACT` node type. And if there is a beta cutoff then the node type must be a `CUT`. But more important than this is that we actually know the corresponding moves for the scores and can directly store the best move in the cache. With this, move ordering could be implemented much more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also a lot more enhancements regarding the used algorithms possible. For instance there is the [MTD(f)](https://www.chessprogramming.org/MTD(f)) algorithm that can be used as an alternative to the Principal Variation Search. Or the move ordering could be enhanced. The chessprogramming wiki defines [several more ways](https://www.chessprogramming.org/Move_Ordering#Typical_move_ordering) what can be taken into account for move ordering. Very important as well is also the evaluation function. The one used here is already very efficient, but does not take into account many other heuristics that many chess players use to evaluate a move. For instance if rooks are positioned on open lines. Then there is also a category of changes that are trade offs and might improve the engines strength or might not. One of them is what moves should be considered in the quiescence search. Most engines do not only consider captures, but also checks. This can detect some case with zugzwang, but also increases the search space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another very important aspect any chess engine that has not been considered in this work, is parallelism. The search could be done on multiple threads and speed up significantly. There are a lot of considerations with multi threading such as thread safety and when it's actually useful to calculate something in a different thread. The node types can help here again. For instance an `ALL` Node is safe to parallelize as all moves have to be analyzed anyway. On a `CUT` Node on the other hand that might not be useful as later moves would have been pruned anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, it would probably be possible to further enhance this engine and reach an ELO of 2000 without changing the language. If the engine was written in a more efficient language higher scores might be realistic as well."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  },
  "vscode": {
   "interpreter": {
    "hash": "c356581f63fdb862d21b8530e2fecebf3d406a06e3d3208273931edc8a0b30c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
